{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9031e8ee",
   "metadata": {},
   "source": [
    "# üêç Snake RL - Guide Complet pour D√©butants\n",
    "\n",
    "## üåü Qu'est-ce que l'Apprentissage par Renforcement ?\n",
    "\n",
    "Imaginez que vous apprenez √† faire du v√©lo :\n",
    "1. **Vous essayez** de p√©daler (action)\n",
    "2. **Vous observez** ce qui se passe (vous tombez ou vous avancez)\n",
    "3. **Vous recevez un retour** (douleur si vous tombez, plaisir si vous avancez)\n",
    "4. **Vous ajustez** votre comportement pour la prochaine fois\n",
    "\n",
    "L'**Apprentissage par Renforcement (RL)** fonctionne exactement pareil ! C'est une m√©thode pour cr√©er des programmes informatiques (des \"agents\") qui apprennent √† prendre de bonnes d√©cisions en interagissant avec leur environnement.\n",
    "\n",
    "## üéÆ Pourquoi Snake ?\n",
    "\n",
    "Le jeu Snake est parfait pour d√©buter en RL car :\n",
    "- **Simple √† comprendre** : mangez des pommes, √©vitez les murs\n",
    "- **D√©cisions claires** : aller tout droit, tourner √† gauche ou √† droite\n",
    "- **Feedback imm√©diat** : vous savez tout de suite si c'est bien ou mal\n",
    "- **Objectif mesurable** : le score (nombre de pommes mang√©es)\n",
    "\n",
    "## ü§ñ Notre Mission\n",
    "\n",
    "Nous allons cr√©er une **Intelligence Artificielle** qui apprend √† jouer √† Snake **toute seule**, sans qu'on lui dise quoi faire ! Elle va :\n",
    "\n",
    "1. **Jouer des milliers de parties** (m√™me mal au d√©but)\n",
    "2. **Observer les r√©sultats** de ses actions\n",
    "3. **M√©moriser** ce qui marche et ce qui ne marche pas\n",
    "4. **S'am√©liorer progressivement** jusqu'√† devenir experte\n",
    "\n",
    "### üß© Les Ingr√©dients de Notre Projet\n",
    "\n",
    "```\n",
    "üéÆ Environnement Snake    +    üß† Agent Intelligent    =    üèÜ IA qui joue √† Snake\n",
    "   (Le jeu lui-m√™me)           (Le cerveau artificiel)        (R√©sultat final)\n",
    "```\n",
    "\n",
    "### üó∫Ô∏è Feuille de Route du Projet\n",
    "\n",
    "1. **üéØ Comprendre** les concepts de base (ce notebook)\n",
    "2. **üîß Installer** le projet sur votre ordinateur  \n",
    "3. **üéÆ Jouer** manuellement pour comprendre le d√©fi\n",
    "4. **üëÄ Observer** l'IA apprendre √©tape par √©tape\n",
    "5. **üìä Analyser** ses performances vs humains\n",
    "6. **üöÄ Exp√©rimenter** avec des am√©liorations\n",
    "\n",
    "### üí° Aucune Exp√©rience Requise !\n",
    "\n",
    "- **Pas besoin** d'√™tre expert en maths\n",
    "- **Pas besoin** d'√™tre d√©veloppeur confirm√©  \n",
    "- **Juste de la curiosit√©** et l'envie d'apprendre !\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Pr√™t √† d√©couvrir comment une machine peut apprendre √† jouer ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f1ef8",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Les Outils dont nous avons Besoin\n",
    "\n",
    "Comme un cuisinier a besoin d'ustensiles, notre projet a besoin d'outils informatiques sp√©cialis√©s. Pas de panique ! Voici ce que chaque outil fait, **en langage simple** :\n",
    "\n",
    "### üß∞ Notre Bo√Æte √† Outils\n",
    "\n",
    "- **üêç Python** : Le langage de programmation (comme l'anglais pour parler aux ordinateurs)\n",
    "- **üéÆ Pygame** : Pour cr√©er l'interface graphique du jeu (les graphismes que vous voyez)\n",
    "- **üß† PyTorch** : La biblioth√®que qui permet √† l'IA d'apprendre (le \"cerveau\" artificiel)\n",
    "- **üìä NumPy & Matplotlib** : Pour les calculs et les graphiques (comme Excel mais en plus puissant)\n",
    "\n",
    "### üîå Pourquoi ces Outils ?\n",
    "\n",
    "- **Pygame** ‚Üí Comme Photoshop, mais pour cr√©er des jeux\n",
    "- **PyTorch** ‚Üí Comme un simulateur de cerveau pour l'IA\n",
    "- **NumPy** ‚Üí Comme une calculatrice super rapide\n",
    "- **Matplotlib** ‚Üí Comme Excel pour faire de beaux graphiques\n",
    "\n",
    "Ne vous inqui√©tez pas si vous ne connaissez pas ces outils - le code est d√©j√† √©crit ! Vous devez juste comprendre le principe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d3f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Chargement des outils...\n",
      "‚úÖ Outils de base charg√©s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ce PC\\Projets\\Apprentissage renforcement\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "‚úÖ Pygame charg√© - On peut dessiner le jeu !\n",
      "‚úÖ NumPy charg√© - On peut faire des calculs rapides !\n",
      "‚úÖ PyTorch charg√© - Notre IA peut maintenant apprendre !\n",
      "    Version PyTorch: 2.7.1+cu118\n",
      "‚úÖ PyTorch charg√© - Notre IA peut maintenant apprendre !\n",
      "    Version PyTorch: 2.7.1+cu118\n",
      "‚úÖ Matplotlib charg√© - On peut faire des graphiques !\n",
      "\n",
      "üéâ Tous les outils sont pr√™ts !\n",
      "\n",
      "üí° RAPPEL : Ces outils sont comme...\n",
      "   üéÆ Pygame = Photoshop pour les jeux\n",
      "   üß† PyTorch = Simulateur de cerveau\n",
      "   üìä NumPy = Calculatrice ultra-rapide\n",
      "   üìà Matplotlib = Excel pour graphiques\n",
      "\n",
      "üöÄ Maintenant nous pouvons cr√©er notre IA qui apprend √† jouer √† Snake !\n",
      "‚úÖ Matplotlib charg√© - On peut faire des graphiques !\n",
      "\n",
      "üéâ Tous les outils sont pr√™ts !\n",
      "\n",
      "üí° RAPPEL : Ces outils sont comme...\n",
      "   üéÆ Pygame = Photoshop pour les jeux\n",
      "   üß† PyTorch = Simulateur de cerveau\n",
      "   üìä NumPy = Calculatrice ultra-rapide\n",
      "   üìà Matplotlib = Excel pour graphiques\n",
      "\n",
      "üöÄ Maintenant nous pouvons cr√©er notre IA qui apprend √† jouer √† Snake !\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Imports n√©cessaires pour le projet Snake RL\n",
    "\"\"\"\n",
    "\n",
    "# üß∞ Chargement de nos outils de travail\n",
    "# (Pas besoin de comprendre chaque ligne - juste le principe g√©n√©ral)\n",
    "\n",
    "print(\"üîß Chargement des outils...\")\n",
    "\n",
    "# === OUTILS DE BASE ===\n",
    "import sys      # Pour parler au syst√®me d'exploitation\n",
    "import os       # Pour g√©rer les fichiers et dossiers\n",
    "import time     # Pour g√©rer le temps (pauses, vitesse du jeu)\n",
    "\n",
    "print(\"‚úÖ Outils de base charg√©s\")\n",
    "\n",
    "# === OUTILS POUR LE JEU ===\n",
    "try:\n",
    "    import pygame    # Pour dessiner le jeu (serpent, pommes, etc.)\n",
    "    print(\"‚úÖ Pygame charg√© - On peut dessiner le jeu !\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Pygame manquant - Installez avec: pip install pygame\")\n",
    "\n",
    "# === OUTILS POUR LES CALCULS ===\n",
    "try:\n",
    "    import numpy as np  # Pour les calculs rapides (positions, scores, etc.)\n",
    "    print(\"‚úÖ NumPy charg√© - On peut faire des calculs rapides !\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå NumPy manquant - Installez avec: pip install numpy\")\n",
    "\n",
    "# === OUTILS POUR L'INTELLIGENCE ARTIFICIELLE ===\n",
    "try:\n",
    "    import torch               # Le cerveau de notre IA\n",
    "    import torch.nn as nn      # Pour construire le r√©seau de neurones\n",
    "    print(\"‚úÖ PyTorch charg√© - Notre IA peut maintenant apprendre !\")\n",
    "    print(f\"    Version PyTorch: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch manquant - Installez avec: pip install torch\")\n",
    "\n",
    "# === OUTILS POUR LES GRAPHIQUES ===\n",
    "try:\n",
    "    import matplotlib.pyplot as plt  # Pour cr√©er de beaux graphiques\n",
    "    print(\"‚úÖ Matplotlib charg√© - On peut faire des graphiques !\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Matplotlib manquant - Installez avec: pip install matplotlib\")\n",
    "\n",
    "print(\"\\nüéâ Tous les outils sont pr√™ts !\")\n",
    "print(\"\\nüí° RAPPEL : Ces outils sont comme...\")\n",
    "print(\"   üéÆ Pygame = Photoshop pour les jeux\")\n",
    "print(\"   üß† PyTorch = Simulateur de cerveau\")\n",
    "print(\"   üìä NumPy = Calculatrice ultra-rapide\") \n",
    "print(\"   üìà Matplotlib = Excel pour graphiques\")\n",
    "\n",
    "print(\"\\nüöÄ Maintenant nous pouvons cr√©er notre IA qui apprend √† jouer √† Snake !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da4cb9",
   "metadata": {},
   "source": [
    "## üöÄ Optimisation GPU - Exploiter la Puissance de votre RTX 4060\n",
    "\n",
    "### üí™ Pourquoi le GPU est Important ?\n",
    "\n",
    "Votre **NVIDIA RTX 4060** est comme un **superordinateur miniature** sp√©cialement con√ßu pour l'Intelligence Artificielle ! Voici pourquoi c'est crucial :\n",
    "\n",
    "- **üêå CPU seul** : Comme faire du calcul avec une calculatrice de poche\n",
    "- **üöÄ RTX 4060** : Comme avoir 1000 calculatrices qui travaillent en parall√®le !\n",
    "\n",
    "### ‚ö° Avantages de votre RTX 4060 pour l'IA\n",
    "\n",
    "- **üíæ 8 GB VRAM** : Assez pour entra√Æner des mod√®les complexes\n",
    "- **üî• Architecture Ada Lovelace** : Optimis√©e pour PyTorch et TensorFlow  \n",
    "- **‚ö° 3072 CUDA Cores** : Calculs parall√®les ultra-rapides\n",
    "- **üéØ RT Cores** : Acc√©l√©ration sp√©cialis√©e pour l'IA\n",
    "\n",
    "### üéØ Configuration Automatique\n",
    "\n",
    "Notre projet d√©tecte **automatiquement** votre RTX 4060 et l'utilise de mani√®re optimale. Plus besoin de configuration manuelle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111b8154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è D√âTECTION DE VOTRE MAT√âRIEL GPU\n",
      "========================================\n",
      "‚úÖ CUDA disponible - GPU pr√™t pour l'IA !\n",
      "üî¢ Nombre de GPU d√©tect√©s : 1\n",
      "\n",
      "üéÆ GPU 0 :\n",
      "   üìõ Nom : NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   üíæ M√©moire : 8.0 GB\n",
      "   üéØ ‚úÖ RTX 4060 TROUV√âE ! (GPU 0)\n",
      "   üî• Multiprocesseurs : 24\n",
      "   ‚ö° CUDA Capability : 8.9\n",
      "\n",
      "========================================\n",
      "üéâ PARFAIT ! Votre RTX 4060 a √©t√© d√©tect√©e !\n",
      "üöÄ L'entra√Ænement utilisera automatiquement le GPU 0\n",
      "‚ö° Vitesse d'entra√Ænement attendue : 10-20x plus rapide qu'en CPU\n",
      "\n",
      "üß™ TEST DE PERFORMANCE GPU :\n",
      "   ‚è±Ô∏è  Temps CPU : 0.027s\n",
      "   ‚ö° Temps GPU : 0.042s\n",
      "   üöÄ Acc√©l√©ration : 0.6x plus rapide !\n",
      "\n",
      "üéØ CONFIGURATION POUR SNAKE RL :\n",
      "‚úÖ Notre agent DQN d√©tectera automatiquement votre RTX 4060\n",
      "‚úÖ Tous les calculs d'entra√Ænement utiliseront le GPU\n",
      "‚úÖ Les tensors seront automatiquement transf√©r√©s sur GPU\n",
      "‚úÖ Optimisations CUDA activ√©es pour maximum de performance\n",
      "\n",
      "‚ö° GAIN DE PERFORMANCE ATTENDU :\n",
      "   üéÆ Entra√Ænement rapide (100 √©pisodes) : 2-3 minutes ‚Üí 30 secondes\n",
      "   üéÆ Entra√Ænement complet (2000 √©pisodes): 2 heures ‚Üí 15-20 minutes\n",
      "   üéÆ Inf√©rence (IA qui joue)            : Instantan√© vs l√©ger d√©lai CPU\n",
      "   üéÆ Exp√©rimentations                   : Tests multiples rapides\n",
      "\n",
      "üîß OPTIMISATIONS AUTOMATIQUES ACTIV√âES :\n",
      "   ‚úÖ D√©tection automatique RTX 4060\n",
      "   ‚úÖ Transfert optimis√© CPU ‚Üî GPU\n",
      "   ‚úÖ CUDA benchmarking pour convolutions\n",
      "   ‚úÖ Gradient accumulation GPU-optimis√©\n",
      "   ‚úÖ Memory management intelligent\n",
      "\n",
      "üèÅ PR√äT POUR L'ENTRA√éNEMENT ACC√âL√âR√â !\n",
      "   Votre RTX 4060 va faire chauffer Snake ! üî•üêç\n",
      "   ‚è±Ô∏è  Temps CPU : 0.027s\n",
      "   ‚ö° Temps GPU : 0.042s\n",
      "   üöÄ Acc√©l√©ration : 0.6x plus rapide !\n",
      "\n",
      "üéØ CONFIGURATION POUR SNAKE RL :\n",
      "‚úÖ Notre agent DQN d√©tectera automatiquement votre RTX 4060\n",
      "‚úÖ Tous les calculs d'entra√Ænement utiliseront le GPU\n",
      "‚úÖ Les tensors seront automatiquement transf√©r√©s sur GPU\n",
      "‚úÖ Optimisations CUDA activ√©es pour maximum de performance\n",
      "\n",
      "‚ö° GAIN DE PERFORMANCE ATTENDU :\n",
      "   üéÆ Entra√Ænement rapide (100 √©pisodes) : 2-3 minutes ‚Üí 30 secondes\n",
      "   üéÆ Entra√Ænement complet (2000 √©pisodes): 2 heures ‚Üí 15-20 minutes\n",
      "   üéÆ Inf√©rence (IA qui joue)            : Instantan√© vs l√©ger d√©lai CPU\n",
      "   üéÆ Exp√©rimentations                   : Tests multiples rapides\n",
      "\n",
      "üîß OPTIMISATIONS AUTOMATIQUES ACTIV√âES :\n",
      "   ‚úÖ D√©tection automatique RTX 4060\n",
      "   ‚úÖ Transfert optimis√© CPU ‚Üî GPU\n",
      "   ‚úÖ CUDA benchmarking pour convolutions\n",
      "   ‚úÖ Gradient accumulation GPU-optimis√©\n",
      "   ‚úÖ Memory management intelligent\n",
      "\n",
      "üèÅ PR√äT POUR L'ENTRA√éNEMENT ACC√âL√âR√â !\n",
      "   Votre RTX 4060 va faire chauffer Snake ! üî•üêç\n"
     ]
    }
   ],
   "source": [
    "# üîç D√âTECTION ET TEST DE VOTRE RTX 4060\n",
    "print(\"üïµÔ∏è D√âTECTION DE VOTRE MAT√âRIEL GPU\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# === V√âRIFICATION CUDA ===\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"‚úÖ CUDA disponible - GPU pr√™t pour l'IA !\")\n",
    "        \n",
    "        # Nombre de GPU\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"üî¢ Nombre de GPU d√©tect√©s : {gpu_count}\")\n",
    "        \n",
    "        # D√©tails de chaque GPU\n",
    "        rtx_4060_found = False\n",
    "        rtx_4060_index = None\n",
    "        \n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            \n",
    "            print(f\"\\nüéÆ GPU {i} :\")\n",
    "            print(f\"   üìõ Nom : {gpu_name}\")\n",
    "            print(f\"   üíæ M√©moire : {gpu_memory:.1f} GB\")\n",
    "            \n",
    "            # Recherche sp√©cifique de la RTX 4060\n",
    "            if \"4060\" in gpu_name or \"RTX 4060\" in gpu_name:\n",
    "                rtx_4060_found = True\n",
    "                rtx_4060_index = i\n",
    "                print(f\"   üéØ ‚úÖ RTX 4060 TROUV√âE ! (GPU {i})\")\n",
    "                \n",
    "                # Informations d√©taill√©es RTX 4060\n",
    "                props = torch.cuda.get_device_properties(i)\n",
    "                print(f\"   üî• Multiprocesseurs : {props.multi_processor_count}\")\n",
    "                print(f\"   ‚ö° CUDA Capability : {props.major}.{props.minor}\")\n",
    "        \n",
    "        # R√©sum√© de d√©tection\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        if rtx_4060_found:\n",
    "            print(f\"üéâ PARFAIT ! Votre RTX 4060 a √©t√© d√©tect√©e !\")\n",
    "            print(f\"üöÄ L'entra√Ænement utilisera automatiquement le GPU {rtx_4060_index}\")\n",
    "            print(f\"‚ö° Vitesse d'entra√Ænement attendue : 10-20x plus rapide qu'en CPU\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  RTX 4060 non d√©tect√©e par nom\")\n",
    "            print(f\"üîÑ Le script utilisera le GPU par d√©faut : GPU 0\")\n",
    "            print(f\"üí° V√©rifiez les drivers NVIDIA et CUDA\")\n",
    "        \n",
    "        # Test de performance basique\n",
    "        print(f\"\\nüß™ TEST DE PERFORMANCE GPU :\")\n",
    "        device = torch.device(f\"cuda:{rtx_4060_index}\" if rtx_4060_found else \"cuda:0\")\n",
    "        \n",
    "        # Test simple de calcul matriciel\n",
    "        import time\n",
    "        matrix_size = 1000\n",
    "        \n",
    "        # Test CPU\n",
    "        start_time = time.time()\n",
    "        a_cpu = torch.randn(matrix_size, matrix_size)\n",
    "        b_cpu = torch.randn(matrix_size, matrix_size)\n",
    "        c_cpu = torch.mm(a_cpu, b_cpu)\n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        # Test GPU\n",
    "        start_time = time.time()\n",
    "        a_gpu = torch.randn(matrix_size, matrix_size, device=device)\n",
    "        b_gpu = torch.randn(matrix_size, matrix_size, device=device)\n",
    "        torch.cuda.synchronize()  # Attendre que le GPU finisse\n",
    "        start_time = time.time()  # Recommencer le chronom√©trage\n",
    "        c_gpu = torch.mm(a_gpu, b_gpu)\n",
    "        torch.cuda.synchronize()  # Attendre la fin\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        speedup = cpu_time / gpu_time\n",
    "        print(f\"   ‚è±Ô∏è  Temps CPU : {cpu_time:.3f}s\")\n",
    "        print(f\"   ‚ö° Temps GPU : {gpu_time:.3f}s\")\n",
    "        print(f\"   üöÄ Acc√©l√©ration : {speedup:.1f}x plus rapide !\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå CUDA non disponible\")\n",
    "        print(\"üí° Solutions possibles :\")\n",
    "        print(\"   ‚Ä¢ Installer/mettre √† jour les drivers NVIDIA\")\n",
    "        print(\"   ‚Ä¢ R√©installer PyTorch avec support CUDA\")\n",
    "        print(\"   ‚Ä¢ V√©rifier que la RTX 4060 est bien reconnue par Windows\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch non install√©\")\n",
    "    print(\"üí° Installez avec : pip install torch\")\n",
    "\n",
    "print(f\"\\nüéØ CONFIGURATION POUR SNAKE RL :\")\n",
    "print(\"‚úÖ Notre agent DQN d√©tectera automatiquement votre RTX 4060\")\n",
    "print(\"‚úÖ Tous les calculs d'entra√Ænement utiliseront le GPU\")\n",
    "print(\"‚úÖ Les tensors seront automatiquement transf√©r√©s sur GPU\")\n",
    "print(\"‚úÖ Optimisations CUDA activ√©es pour maximum de performance\")\n",
    "\n",
    "print(f\"\\n‚ö° GAIN DE PERFORMANCE ATTENDU :\")\n",
    "performance_gains = {\n",
    "    \"Entra√Ænement rapide (100 √©pisodes)\": \"2-3 minutes ‚Üí 30 secondes\",\n",
    "    \"Entra√Ænement complet (2000 √©pisodes)\": \"2 heures ‚Üí 15-20 minutes\",\n",
    "    \"Inf√©rence (IA qui joue)\": \"Instantan√© vs l√©ger d√©lai CPU\",\n",
    "    \"Exp√©rimentations\": \"Tests multiples rapides\"\n",
    "}\n",
    "\n",
    "for task, improvement in performance_gains.items():\n",
    "    print(f\"   üéÆ {task:<35}: {improvement}\")\n",
    "\n",
    "print(f\"\\nüîß OPTIMISATIONS AUTOMATIQUES ACTIV√âES :\")\n",
    "optimizations = [\n",
    "    \"D√©tection automatique RTX 4060\",\n",
    "    \"Transfert optimis√© CPU ‚Üî GPU\", \n",
    "    \"CUDA benchmarking pour convolutions\",\n",
    "    \"Gradient accumulation GPU-optimis√©\",\n",
    "    \"Memory management intelligent\"\n",
    "]\n",
    "\n",
    "for opt in optimizations:\n",
    "    print(f\"   ‚úÖ {opt}\")\n",
    "\n",
    "print(f\"\\nüèÅ PR√äT POUR L'ENTRA√éNEMENT ACC√âL√âR√â !\")\n",
    "print(\"   Votre RTX 4060 va faire chauffer Snake ! üî•üêç\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298be903",
   "metadata": {},
   "source": [
    "### üîß Comment V√©rifier que Votre RTX 4060 est Utilis√©e\n",
    "\n",
    "#### üß™ Test Automatique Complet\n",
    "\n",
    "Un script sp√©cialis√© `test_gpu.py` a √©t√© cr√©√© pour v√©rifier votre configuration :\n",
    "\n",
    "```bash\n",
    "python test_gpu.py\n",
    "```\n",
    "\n",
    "**Ce script teste :**\n",
    "- ‚úÖ D√©tection de votre RTX 4060\n",
    "- ‚úÖ Performance GPU vs CPU  \n",
    "- ‚úÖ Utilisation m√©moire optimale\n",
    "- ‚úÖ Configuration de l'agent DQN\n",
    "\n",
    "#### üìä Pendant l'Entra√Ænement\n",
    "\n",
    "Surveillez ces indicateurs qui confirment l'utilisation GPU :\n",
    "\n",
    "**üü¢ Signes que le GPU fonctionne :**\n",
    "- Message \"Using device: cuda:X\"\n",
    "- \"RTX 4060 d√©tect√©e\" au d√©marrage\n",
    "- Entra√Ænement rapide (5-10 minutes au lieu d'1-2h)\n",
    "- Ventilateurs GPU qui tournent plus fort\n",
    "\n",
    "**üî¥ Signes de probl√®me :**\n",
    "- Message \"Using device: cpu\"\n",
    "- Entra√Ænement tr√®s lent\n",
    "- GPU idle dans le gestionnaire des t√¢ches\n",
    "\n",
    "#### ‚ö° Gains de Performance Attendus\n",
    "\n",
    "Avec votre RTX 4060, vous devriez observer :\n",
    "\n",
    "| T√¢che | CPU seul | RTX 4060 | Gain |\n",
    "|-------|----------|----------|------|\n",
    "| Quick Train (100 √©pisodes) | 5-10 min | 30-60 sec | **10x** |\n",
    "| Full Training (2000 √©pisodes) | 2-3 heures | 15-20 min | **8-10x** |\n",
    "| Inf√©rence (IA qui joue) | 50-100 FPS | 200+ FPS | **3-4x** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a9623",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Le Terrain de Jeu - Comment l'IA \"Voit\" Snake\n",
    "\n",
    "### üßê Le D√©fi de l'IA\n",
    "\n",
    "Imaginez que vous jouez √† Snake avec un bandeau sur les yeux ! L'IA ne \"voit\" pas le jeu comme nous. Elle ne voit pas :\n",
    "- ‚ùå Le serpent vert\n",
    "- ‚ùå La pomme rouge  \n",
    "- ‚ùå Les murs\n",
    "\n",
    "### üëÄ Ce que l'IA \"Voit\" Vraiment\n",
    "\n",
    "Au lieu de √ßa, l'IA re√ßoit des **nombres** qui d√©crivent la situation :\n",
    "\n",
    "```\n",
    "Exemple de ce que \"voit\" l'IA :\n",
    "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
    "```\n",
    "\n",
    "Chaque nombre (0 ou 1) r√©pond √† une question simple :\n",
    "\n",
    "### üß† Les 11 Questions que se Pose l'IA\n",
    "\n",
    "**Questions sur le DANGER :**\n",
    "1. \"Y a-t-il un danger si je continue tout droit ?\" (1=oui, 0=non)\n",
    "2. \"Y a-t-il un danger si je tourne √† droite ?\" (1=oui, 0=non)  \n",
    "3. \"Y a-t-il un danger si je tourne √† gauche ?\" (1=oui, 0=non)\n",
    "\n",
    "**Questions sur ma DIRECTION actuelle :**\n",
    "4. \"Est-ce que je vais vers la gauche ?\" (1=oui, 0=non)\n",
    "5. \"Est-ce que je vais vers la droite ?\" (1=oui, 0=non)\n",
    "6. \"Est-ce que je vais vers le haut ?\" (1=oui, 0=non)\n",
    "7. \"Est-ce que je vais vers le bas ?\" (1=oui, 0=non)\n",
    "\n",
    "**Questions sur la NOURRITURE :**\n",
    "8. \"La pomme est-elle √† ma gauche ?\" (1=oui, 0=non)\n",
    "9. \"La pomme est-elle √† ma droite ?\" (1=oui, 0=non)\n",
    "10. \"La pomme est-elle au-dessus de moi ?\" (1=oui, 0=non)\n",
    "11. \"La pomme est-elle en-dessous de moi ?\" (1=oui, 0=non)\n",
    "\n",
    "### üéØ Les Actions Possibles\n",
    "\n",
    "L'IA peut choisir parmi **3 actions** seulement :\n",
    "- **Action 0** : \"Continue tout droit\"\n",
    "- **Action 1** : \"Tourne √† droite\"  \n",
    "- **Action 2** : \"Tourne √† gauche\"\n",
    "\n",
    "### üèÜ Le Syst√®me de R√©compenses\n",
    "\n",
    "L'IA apprend gr√¢ce aux \"notes\" qu'elle re√ßoit :\n",
    "- **+10 points** ‚Üí \"Bravo ! Tu as mang√© une pomme !\" üçé\n",
    "- **-10 points** ‚Üí \"A√Øe ! Tu es mort...\" ‚ò†Ô∏è\n",
    "- **0 point** ‚Üí \"Mouvement normal, continue...\" ‚û°Ô∏è\n",
    "\n",
    "C'est comme dresser un chien : r√©compense pour les bonnes actions, punition pour les mauvaises !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbf6113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ D√âCODONS LE LANGAGE DE L'IA\n",
      "========================================\n",
      "üêç SITUATION : Le serpent va vers la DROITE\n",
      "üçé La pomme est en BAS √Ä DROITE du serpent\n",
      "‚ö†Ô∏è  Il y a un DANGER √† droite (mur ou corps)\n",
      "\n",
      "ü§ñ Ce que voit l'IA : [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "\n",
      "üîç TRADUCTION EN FRAN√áAIS :\n",
      "   ‚≠ï Position  0: Danger tout droit ?  ‚Üí Non\n",
      "   ‚úÖ Position  1: Danger √† droite ?    ‚Üí OUI\n",
      "   ‚≠ï Position  2: Danger √† gauche ?    ‚Üí Non\n",
      "   ‚≠ï Position  3: Je vais √† gauche ?   ‚Üí Non\n",
      "   ‚úÖ Position  4: Je vais √† droite ?   ‚Üí OUI\n",
      "   ‚≠ï Position  5: Je vais en haut ?    ‚Üí Non\n",
      "   ‚≠ï Position  6: Je vais en bas ?     ‚Üí Non\n",
      "   ‚≠ï Position  7: Pomme √† gauche ?     ‚Üí Non\n",
      "   ‚úÖ Position  8: Pomme √† droite ?     ‚Üí OUI\n",
      "   ‚≠ï Position  9: Pomme en haut ?      ‚Üí Non\n",
      "   ‚úÖ Position 10: Pomme en bas ?       ‚Üí OUI\n",
      "\n",
      "üß† R√âFLEXION DE L'IA :\n",
      "   üí≠ 'Je vais √† droite mais il y a un danger √† droite...'\n",
      "   üí≠ 'La pomme est √† droite ET en bas...'\n",
      "   üí≠ 'Je devrais peut-√™tre aller tout droit ou √† gauche ?'\n",
      "\n",
      "üéØ ACTIONS POSSIBLES :\n",
      "   ‚úÖ Action 0: Continuer tout droit (pas de danger)\n",
      "   ‚ùå Action 1: Tourner √† droite (DANGER!)\n",
      "   ‚ö†Ô∏è  Action 2: Tourner √† gauche (s√ªr, mais s'√©loigne de la pomme)\n",
      "\n",
      "üèÜ SYST√àME DE NOTES :\n",
      "   üçé Manger pomme ‚Üí +10 points (Excellent !)\n",
      "   ‚ò†Ô∏è  Mourir ‚Üí -10 points (Tr√®s mal !)\n",
      "   ‚û°Ô∏è  Bouger normalement ‚Üí 0 point (Neutre)\n",
      "\n",
      "üí° ASTUCE POUR COMPRENDRE :\n",
      "   L'IA ne 'voit' pas d'images comme nous !\n",
      "   Elle ne comprend que les CHIFFRES.\n",
      "   C'est comme jouer √† Snake en √©tant aveugle,\n",
      "   avec quelqu'un qui vous dit juste :\n",
      "   'Danger √† droite ! Pomme en bas !'\n"
     ]
    }
   ],
   "source": [
    "# üîç D√©monstration : Comment l'IA \"lit\" le jeu\n",
    "import numpy as np\n",
    "\n",
    "print(\"üéÆ D√âCODONS LE LANGAGE DE L'IA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Simulons une situation de jeu\n",
    "print(\"üêç SITUATION : Le serpent va vers la DROITE\")\n",
    "print(\"üçé La pomme est en BAS √Ä DROITE du serpent\")\n",
    "print(\"‚ö†Ô∏è  Il y a un DANGER √† droite (mur ou corps)\")\n",
    "\n",
    "# Voici ce que \"voit\" l'IA dans cette situation :\n",
    "etat_ia = [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
    "print(f\"\\nü§ñ Ce que voit l'IA : {etat_ia}\")\n",
    "\n",
    "print(\"\\nüîç TRADUCTION EN FRAN√áAIS :\")\n",
    "questions = [\n",
    "    \"Danger tout droit ?\",      # Position 0 ‚Üí 0 (non)\n",
    "    \"Danger √† droite ?\",        # Position 1 ‚Üí 1 (OUI!)\n",
    "    \"Danger √† gauche ?\",        # Position 2 ‚Üí 0 (non)\n",
    "    \"Je vais √† gauche ?\",       # Position 3 ‚Üí 0 (non)\n",
    "    \"Je vais √† droite ?\",       # Position 4 ‚Üí 1 (OUI!)\n",
    "    \"Je vais en haut ?\",        # Position 5 ‚Üí 0 (non)\n",
    "    \"Je vais en bas ?\",         # Position 6 ‚Üí 0 (non)\n",
    "    \"Pomme √† gauche ?\",         # Position 7 ‚Üí 0 (non)\n",
    "    \"Pomme √† droite ?\",         # Position 8 ‚Üí 1 (OUI!)\n",
    "    \"Pomme en haut ?\",          # Position 9 ‚Üí 0 (non)\n",
    "    \"Pomme en bas ?\"           # Position 10 ‚Üí 1 (OUI!)\n",
    "]\n",
    "\n",
    "for i, (question, valeur) in enumerate(zip(questions, etat_ia)):\n",
    "    if valeur == 1:\n",
    "        print(f\"   ‚úÖ Position {i:2d}: {question:<20} ‚Üí OUI\")\n",
    "    else:\n",
    "        print(f\"   ‚≠ï Position {i:2d}: {question:<20} ‚Üí Non\")\n",
    "\n",
    "print(f\"\\nüß† R√âFLEXION DE L'IA :\")\n",
    "print(\"   üí≠ 'Je vais √† droite mais il y a un danger √† droite...'\")\n",
    "print(\"   üí≠ 'La pomme est √† droite ET en bas...'\")\n",
    "print(\"   üí≠ 'Je devrais peut-√™tre aller tout droit ou √† gauche ?'\")\n",
    "\n",
    "print(f\"\\nüéØ ACTIONS POSSIBLES :\")\n",
    "actions_possibles = {\n",
    "    0: \"Continuer tout droit (pas de danger)\",\n",
    "    1: \"Tourner √† droite (DANGER!)\",\n",
    "    2: \"Tourner √† gauche (s√ªr, mais s'√©loigne de la pomme)\"\n",
    "}\n",
    "\n",
    "for action_id, description in actions_possibles.items():\n",
    "    if \"DANGER\" in description:\n",
    "        print(f\"   ‚ùå Action {action_id}: {description}\")\n",
    "    elif \"tout droit\" in description:\n",
    "        print(f\"   ‚úÖ Action {action_id}: {description}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Action {action_id}: {description}\")\n",
    "\n",
    "print(f\"\\nüèÜ SYST√àME DE NOTES :\")\n",
    "print(\"   üçé Manger pomme ‚Üí +10 points (Excellent !)\")\n",
    "print(\"   ‚ò†Ô∏è  Mourir ‚Üí -10 points (Tr√®s mal !)\")\n",
    "print(\"   ‚û°Ô∏è  Bouger normalement ‚Üí 0 point (Neutre)\")\n",
    "\n",
    "print(f\"\\nüí° ASTUCE POUR COMPRENDRE :\")\n",
    "print(\"   L'IA ne 'voit' pas d'images comme nous !\")\n",
    "print(\"   Elle ne comprend que les CHIFFRES.\")\n",
    "print(\"   C'est comme jouer √† Snake en √©tant aveugle,\")\n",
    "print(\"   avec quelqu'un qui vous dit juste :\")\n",
    "print(\"   'Danger √† droite ! Pomme en bas !'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc3fe0",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Le Cerveau Artificiel - Comment l'IA Prend ses D√©cisions\n",
    "\n",
    "### üß† Qu'est-ce qu'un \"R√©seau de Neurones\" ?\n",
    "\n",
    "Imaginez le cerveau humain comme une √©norme centrale t√©l√©phonique :\n",
    "- Des **neurones** (comme des op√©rateurs t√©l√©phoniques)\n",
    "- Des **connexions** entre eux (comme des fils t√©l√©phoniques)\n",
    "- Des **signaux** qui passent de l'un √† l'autre\n",
    "\n",
    "### üîó Notre R√©seau Artificiel\n",
    "\n",
    "Nous cr√©ons une **version simplifi√©e** de ce syst√®me :\n",
    "\n",
    "```\n",
    "üî¢ ENTR√âE (11 nombres)    ‚Üí    üß† TRAITEMENT    ‚Üí    üéØ SORTIE (3 choix)\n",
    "   [0,1,0,1,0...]              (2 couches        [Score action 0]\n",
    "   Questions sur               de 256 neurones    [Score action 1] \n",
    "   le jeu                      chacune)          [Score action 2]\n",
    "```\n",
    "\n",
    "### üè≠ Comment √ßa Marche ? (M√©taphore de l'Usine)\n",
    "\n",
    "1. **üö™ Entr√©e** : Les 11 questions arrivent √† l'usine\n",
    "2. **‚öôÔ∏è Premi√®re machine** : 256 \"ouvriers\" analysent ces infos\n",
    "3. **‚öôÔ∏è Deuxi√®me machine** : 256 autres \"ouvriers\" affinent l'analyse  \n",
    "4. **üìä Sortie** : 3 \"contrema√Ætres\" donnent une note √† chaque action\n",
    "\n",
    "### üéØ Les Notes de Sortie\n",
    "\n",
    "L'IA ne dit pas \"je choisis l'action 1\", elle dit :\n",
    "- **Action 0** (tout droit) : Note de 7.2/10\n",
    "- **Action 1** (droite) : Note de 2.1/10  \n",
    "- **Action 2** (gauche) : Note de 8.9/10\n",
    "\n",
    "‚Üí Elle choisit l'action avec la **meilleure note** (ici : gauche)\n",
    "\n",
    "### üé≤ Le Dilemme : Explorer ou Exploiter ?\n",
    "\n",
    "**Probl√®me** : Si l'IA choisit toujours la meilleure action connue, elle n'apprendra jamais de nouvelles strat√©gies !\n",
    "\n",
    "**Solution** : Le syst√®me \"Œµ-epsilon\" (comme lancer une pi√®ce)\n",
    "- **90% du temps** ‚Üí Choisir la meilleure action (exploitation)\n",
    "- **10% du temps** ‚Üí Choisir au hasard (exploration)\n",
    "\n",
    "Au d√©but : 100% exploration (l'IA ne sait rien)\n",
    "√Ä la fin : 1% exploration (l'IA est experte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbd5ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† ARCHITECTURE DU R√âSEAU DQN:\n",
      "========================================\n",
      "DemoQNetwork(\n",
      "  (linear1): Linear(in_features=11, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (linear3): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "üìä STATISTIQUES DU R√âSEAU:\n",
      "   ‚Ä¢ Param√®tres totaux: 69,635\n",
      "   ‚Ä¢ Param√®tres entra√Ænables: 69,635\n",
      "\n",
      "üß™ TEST DU R√âSEAU:\n",
      "√âtat d'entr√©e: [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "Q-values de sortie: [ 0.04762428 -0.01428808 -0.09098528]\n",
      "Meilleure action: 0 (Tout droit)\n",
      "\n",
      "‚öôÔ∏è HYPERPARAM√àTRES TYPIQUES:\n",
      "   ‚Ä¢ Learning Rate       : 0.001\n",
      "   ‚Ä¢ Gamma (discount)    : 0.9\n",
      "   ‚Ä¢ Epsilon (exploration): 1.0 ‚Üí 0.01\n",
      "   ‚Ä¢ Batch Size          : 32\n",
      "   ‚Ä¢ Replay Buffer       : 10,000 exp√©riences\n",
      "   ‚Ä¢ Target Update       : Toutes les 1000 √©tapes\n"
     ]
    }
   ],
   "source": [
    "# D√©monstration de l'architecture DQN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DemoQNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    R√©seau de neurones pour l'agent DQN (version simplifi√©e pour d√©monstration)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=11, hidden_size=256, output_size=3):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Couche 1 : Input ‚Üí Hidden1 (avec ReLU)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        # Couche 2 : Hidden1 ‚Üí Hidden2 (avec ReLU)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        # Couche 3 : Hidden2 ‚Üí Output (Q-values)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# Cr√©er une instance du r√©seau\n",
    "demo_network = DemoQNetwork()\n",
    "\n",
    "print(\"üß† ARCHITECTURE DU R√âSEAU DQN:\")\n",
    "print(\"=\"*40)\n",
    "print(demo_network)\n",
    "\n",
    "# Calculer le nombre de param√®tres\n",
    "total_params = sum(p.numel() for p in demo_network.parameters())\n",
    "trainable_params = sum(p.numel() for p in demo_network.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES DU R√âSEAU:\")\n",
    "print(f\"   ‚Ä¢ Param√®tres totaux: {total_params:,}\")\n",
    "print(f\"   ‚Ä¢ Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "\n",
    "# D√©monstration avec un √©tat exemple\n",
    "print(f\"\\nüß™ TEST DU R√âSEAU:\")\n",
    "exemple_etat = torch.FloatTensor([[0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]])\n",
    "print(f\"√âtat d'entr√©e: {exemple_etat.numpy()[0]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    q_values = demo_network(exemple_etat)\n",
    "    print(f\"Q-values de sortie: {q_values.numpy()[0]}\")\n",
    "    \n",
    "    # Trouver la meilleure action\n",
    "    best_action = q_values.argmax().item()\n",
    "    action_names = [\"Tout droit\", \"Droite\", \"Gauche\"]\n",
    "    print(f\"Meilleure action: {best_action} ({action_names[best_action]})\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è HYPERPARAM√àTRES TYPIQUES:\")\n",
    "hyperparams = {\n",
    "    \"Learning Rate\": \"0.001\",\n",
    "    \"Gamma (discount)\": \"0.9\", \n",
    "    \"Epsilon (exploration)\": \"1.0 ‚Üí 0.01\",\n",
    "    \"Batch Size\": \"32\",\n",
    "    \"Replay Buffer\": \"10,000 exp√©riences\",\n",
    "    \"Target Update\": \"Toutes les 1000 √©tapes\"\n",
    "}\n",
    "\n",
    "for param, value in hyperparams.items():\n",
    "    print(f\"   ‚Ä¢ {param:<20}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cee85",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Mode de Jeu Manuel - Interface Humaine\n",
    "\n",
    "Le mode manuel permet aux humains de jouer au Snake pour √©tablir des r√©f√©rences de performance et tester l'environnement. C'est un excellent moyen de comprendre la difficult√© du jeu et de comparer les performances avec l'IA.\n",
    "\n",
    "### üéÆ Fonctionnalit√©s du Mode Manuel\n",
    "\n",
    "- **Contr√¥les intuitifs** : Fl√®ches directionnelles pour d√©placer le serpent\n",
    "- **Interface graphique** : Affichage en temps r√©el avec Pygame\n",
    "- **Statistiques** : Score et longueur du serpent affich√©s\n",
    "- **Niveaux de difficult√©** : Vitesse ajustable (facile, normal, difficile)\n",
    "- **Gestion des collisions** : D√©tection automatique des fins de partie\n",
    "\n",
    "### üéØ Analyse du Code `play_manual.py`\n",
    "\n",
    "Examinons les composants principaux de l'impl√©mentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103f0017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ COMPOSANTS PRINCIPAUX DE ManualSnakeGame\n",
      "==================================================\n",
      "1Ô∏è‚É£ INITIALISATION (__init__):\n",
      "   ‚Ä¢ pygame.init() - Initialise Pygame\n",
      "   ‚Ä¢ Configuration fen√™tre (640x480)\n",
      "   ‚Ä¢ D√©finition des couleurs (RGB)\n",
      "   ‚Ä¢ Cr√©ation des polices de texte\n",
      "   ‚Ä¢ Appel de reset_game()\n",
      "\n",
      "2Ô∏è‚É£ R√âINITIALISATION (reset_game):\n",
      "   ‚Ä¢ Position initiale serpent: centre √©cran\n",
      "   ‚Ä¢ Serpent initial: 3 segments\n",
      "   ‚Ä¢ Direction: DROITE\n",
      "   ‚Ä¢ Score: 0\n",
      "   ‚Ä¢ Placement al√©atoire nourriture\n",
      "\n",
      "3Ô∏è‚É£ GESTION ENTR√âES (handle_input):\n",
      "   ‚Ä¢ pygame.event.get() - Capture √©v√©nements\n",
      "   ‚Ä¢ ESC: Quitter le jeu\n",
      "   ‚Ä¢ ESPACE: Red√©marrer partie\n",
      "   ‚Ä¢ Fl√®ches: Changer direction (anti-retour)\n",
      "\n",
      "4Ô∏è‚É£ D√âPLACEMENT (move_snake):\n",
      "   ‚Ä¢ Calcul nouvelle position t√™te\n",
      "   ‚Ä¢ V√©rification collisions\n",
      "   ‚Ä¢ Ajout nouvelle t√™te au serpent\n",
      "   ‚Ä¢ Test si nourriture mang√©e\n",
      "   ‚Ä¢ Suppression queue (si pas de croissance)\n",
      "\n",
      "5Ô∏è‚É£ COLLISIONS (check_collision):\n",
      "   ‚Ä¢ Bords de l'√©cran: x<0, x>=width, y<0, y>=height\n",
      "   ‚Ä¢ Auto-collision: t√™te touche le corps\n",
      "   ‚Ä¢ Retour: True/False\n",
      "\n",
      "6Ô∏è‚É£ AFFICHAGE (draw):\n",
      "   ‚Ä¢ Remplissage fond noir\n",
      "   ‚Ä¢ Dessin serpent: t√™te jaune/verte, corps vert/bleu\n",
      "   ‚Ä¢ Dessin nourriture rouge\n",
      "   ‚Ä¢ Affichage score et longueur\n",
      "   ‚Ä¢ Messages game over et instructions\n",
      "\n",
      "7Ô∏è‚É£ BOUCLE PRINCIPALE (run):\n",
      "   ‚Ä¢ while running: Boucle infinie\n",
      "   ‚Ä¢ handle_input() - Traiter les entr√©es\n",
      "   ‚Ä¢ move_snake() - D√©placer le serpent\n",
      "   ‚Ä¢ draw() - Dessiner le jeu\n",
      "   ‚Ä¢ clock.tick(speed) - Contr√¥ler la vitesse\n",
      "\n",
      "üéöÔ∏è NIVEAUX DE DIFFICULT√â:\n",
      "   ‚Ä¢ Facile: 6 FPS - Id√©al pour d√©buter\n",
      "   ‚Ä¢ Normal: 10 FPS - √âquilibr√© pour la plupart des joueurs\n",
      "   ‚Ä¢ Difficile: 15 FPS - Challenge pour experts\n",
      "\n",
      "üèÜ M√âTRIQUES DE PERFORMANCE:\n",
      "   ‚Ä¢ Score = Nombre de pommes mang√©es\n",
      "   ‚Ä¢ Longueur = Taille du serpent (initial: 3)\n",
      "   ‚Ä¢ Survie = Nombre de mouvements avant collision\n",
      "   ‚Ä¢ Efficacit√© = Score / Mouvements totaux\n"
     ]
    }
   ],
   "source": [
    "# Analyse des composants cl√©s du mode manuel\n",
    "print(\"üéÆ COMPOSANTS PRINCIPAUX DE ManualSnakeGame\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Initialisation et configuration\n",
    "class AnalyseManuelGame:\n",
    "    \"\"\"Analyse simplifi√©e de la classe ManualSnakeGame\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"1Ô∏è‚É£ INITIALISATION (__init__):\")\n",
    "        print(\"   ‚Ä¢ pygame.init() - Initialise Pygame\")\n",
    "        print(\"   ‚Ä¢ Configuration fen√™tre (640x480)\")\n",
    "        print(\"   ‚Ä¢ D√©finition des couleurs (RGB)\")\n",
    "        print(\"   ‚Ä¢ Cr√©ation des polices de texte\")\n",
    "        print(\"   ‚Ä¢ Appel de reset_game()\")\n",
    "        \n",
    "    def reset_game_info(self):\n",
    "        print(\"\\n2Ô∏è‚É£ R√âINITIALISATION (reset_game):\")\n",
    "        print(\"   ‚Ä¢ Position initiale serpent: centre √©cran\")\n",
    "        print(\"   ‚Ä¢ Serpent initial: 3 segments\")\n",
    "        print(\"   ‚Ä¢ Direction: DROITE\") \n",
    "        print(\"   ‚Ä¢ Score: 0\")\n",
    "        print(\"   ‚Ä¢ Placement al√©atoire nourriture\")\n",
    "        \n",
    "    def handle_input_info(self):\n",
    "        print(\"\\n3Ô∏è‚É£ GESTION ENTR√âES (handle_input):\")\n",
    "        print(\"   ‚Ä¢ pygame.event.get() - Capture √©v√©nements\")\n",
    "        print(\"   ‚Ä¢ ESC: Quitter le jeu\")\n",
    "        print(\"   ‚Ä¢ ESPACE: Red√©marrer partie\")\n",
    "        print(\"   ‚Ä¢ Fl√®ches: Changer direction (anti-retour)\")\n",
    "        \n",
    "    def move_snake_info(self):\n",
    "        print(\"\\n4Ô∏è‚É£ D√âPLACEMENT (move_snake):\")\n",
    "        print(\"   ‚Ä¢ Calcul nouvelle position t√™te\")\n",
    "        print(\"   ‚Ä¢ V√©rification collisions\")\n",
    "        print(\"   ‚Ä¢ Ajout nouvelle t√™te au serpent\")\n",
    "        print(\"   ‚Ä¢ Test si nourriture mang√©e\")\n",
    "        print(\"   ‚Ä¢ Suppression queue (si pas de croissance)\")\n",
    "        \n",
    "    def collision_info(self):\n",
    "        print(\"\\n5Ô∏è‚É£ COLLISIONS (check_collision):\")\n",
    "        print(\"   ‚Ä¢ Bords de l'√©cran: x<0, x>=width, y<0, y>=height\")\n",
    "        print(\"   ‚Ä¢ Auto-collision: t√™te touche le corps\")\n",
    "        print(\"   ‚Ä¢ Retour: True/False\")\n",
    "        \n",
    "    def draw_info(self):\n",
    "        print(\"\\n6Ô∏è‚É£ AFFICHAGE (draw):\")\n",
    "        print(\"   ‚Ä¢ Remplissage fond noir\")\n",
    "        print(\"   ‚Ä¢ Dessin serpent: t√™te jaune/verte, corps vert/bleu\")\n",
    "        print(\"   ‚Ä¢ Dessin nourriture rouge\")\n",
    "        print(\"   ‚Ä¢ Affichage score et longueur\")\n",
    "        print(\"   ‚Ä¢ Messages game over et instructions\")\n",
    "        \n",
    "    def main_loop_info(self):\n",
    "        print(\"\\n7Ô∏è‚É£ BOUCLE PRINCIPALE (run):\")\n",
    "        print(\"   ‚Ä¢ while running: Boucle infinie\")\n",
    "        print(\"   ‚Ä¢ handle_input() - Traiter les entr√©es\")\n",
    "        print(\"   ‚Ä¢ move_snake() - D√©placer le serpent\")\n",
    "        print(\"   ‚Ä¢ draw() - Dessiner le jeu\") \n",
    "        print(\"   ‚Ä¢ clock.tick(speed) - Contr√¥ler la vitesse\")\n",
    "\n",
    "# D√©monstration de l'analyse\n",
    "analyse = AnalyseManuelGame()\n",
    "analyse.reset_game_info()\n",
    "analyse.handle_input_info()\n",
    "analyse.move_snake_info()\n",
    "analyse.collision_info()\n",
    "analyse.draw_info()\n",
    "analyse.main_loop_info()\n",
    "\n",
    "print(\"\\nüéöÔ∏è NIVEAUX DE DIFFICULT√â:\")\n",
    "difficulty_levels = {\n",
    "    \"Facile\": {\"speed\": 6, \"description\": \"Id√©al pour d√©buter\"},\n",
    "    \"Normal\": {\"speed\": 10, \"description\": \"√âquilibr√© pour la plupart des joueurs\"},\n",
    "    \"Difficile\": {\"speed\": 15, \"description\": \"Challenge pour experts\"}\n",
    "}\n",
    "\n",
    "for level, info in difficulty_levels.items():\n",
    "    print(f\"   ‚Ä¢ {level}: {info['speed']} FPS - {info['description']}\")\n",
    "\n",
    "print(\"\\nüèÜ M√âTRIQUES DE PERFORMANCE:\")\n",
    "print(\"   ‚Ä¢ Score = Nombre de pommes mang√©es\")\n",
    "print(\"   ‚Ä¢ Longueur = Taille du serpent (initial: 3)\")\n",
    "print(\"   ‚Ä¢ Survie = Nombre de mouvements avant collision\")\n",
    "print(\"   ‚Ä¢ Efficacit√© = Score / Mouvements totaux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e5d5f",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Processus d'Entra√Ænement - Apprentissage de l'IA\n",
    "\n",
    "L'entra√Ænement est le c≈ìur de l'apprentissage par renforcement. C'est l√† que l'agent DQN apprend progressivement √† jouer au Snake en explorant l'environnement et en optimisant ses d√©cisions.\n",
    "\n",
    "### üîÑ Cycle d'Apprentissage\n",
    "\n",
    "```\n",
    "1. √âtat initial ‚Üí 2. Choisir action ‚Üí 3. Ex√©cuter action ‚Üí 4. Observer r√©sultat\n",
    "    ‚Üë                                                           ‚Üì\n",
    "8. R√©p√©ter ‚Üê 7. Mettre √† jour r√©seau ‚Üê 6. Entra√Æner ‚Üê 5. Stocker exp√©rience\n",
    "```\n",
    "\n",
    "### üìä M√©triques d'Entra√Ænement\n",
    "\n",
    "- **Score par √©pisode** : Performance imm√©diate\n",
    "- **Score moyen** : Tendance d'apprentissage \n",
    "- **Epsilon** : Niveau d'exploration actuel\n",
    "- **Loss** : Erreur du r√©seau de neurones\n",
    "- **Taille du buffer** : Exp√©riences stock√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation du processus d'entra√Ænement\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_training_progress(episodes=2000):\n",
    "    \"\"\"Simule l'√©volution typique de l'entra√Ænement DQN\"\"\"\n",
    "    \n",
    "    # Simulation des scores au cours de l'entra√Ænement\n",
    "    scores = []\n",
    "    epsilons = []\n",
    "    \n",
    "    # Param√®tres de simulation\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    epsilon_min = 0.01\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        # Phase d'exploration (√©pisodes 0-500)\n",
    "        if episode < 500:\n",
    "            base_score = 0 + (episode / 500) * 2  # Progression lente\n",
    "            noise = np.random.normal(0, 1.5)\n",
    "        # Phase d'apprentissage (√©pisodes 500-1500)\n",
    "        elif episode < 1500:\n",
    "            base_score = 2 + ((episode - 500) / 1000) * 8  # Apprentissage rapide\n",
    "            noise = np.random.normal(0, 2)\n",
    "        # Phase de convergence (√©pisodes 1500+)\n",
    "        else:\n",
    "            base_score = 10 + ((episode - 1500) / 500) * 5  # Am√©lioration lente\n",
    "            noise = np.random.normal(0, 3)\n",
    "        \n",
    "        score = max(0, base_score + noise)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # D√©croissance d'epsilon\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "        epsilons.append(epsilon)\n",
    "    \n",
    "    return scores, epsilons\n",
    "\n",
    "# G√©n√©rer les donn√©es simul√©es\n",
    "scores, epsilons = simulate_training_progress()\n",
    "\n",
    "print(\"üìà SIMULATION D'ENTRA√éNEMENT DQN\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Cr√©er les graphiques\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Graphique 1: √âvolution des scores\n",
    "ax1.plot(scores, alpha=0.6, color='blue', linewidth=0.8)\n",
    "# Moyenne mobile\n",
    "window = 100\n",
    "moving_avg = [np.mean(scores[max(0, i-window):i+1]) for i in range(len(scores))]\n",
    "ax1.plot(moving_avg, color='red', linewidth=2, label='Moyenne mobile (100)')\n",
    "ax1.set_title('√âvolution du Score pendant l\\'Entra√Ænement')\n",
    "ax1.set_xlabel('√âpisode')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: D√©croissance d'Epsilon\n",
    "ax2.plot(epsilons, color='green', linewidth=2)\n",
    "ax2.set_title('D√©croissance d\\'Epsilon (Exploration)')\n",
    "ax2.set_xlabel('√âpisode')\n",
    "ax2.set_ylabel('Epsilon')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 3: Distribution des scores par phase\n",
    "phases = ['Exploration\\n(0-500)', 'Apprentissage\\n(500-1500)', 'Convergence\\n(1500+)']\n",
    "phase_scores = [scores[0:500], scores[500:1500], scores[1500:]]\n",
    "ax3.boxplot(phase_scores, labels=phases)\n",
    "ax3.set_title('Distribution des Scores par Phase')\n",
    "ax3.set_ylabel('Score')\n",
    "\n",
    "# Graphique 4: Performance cumulative\n",
    "cumulative_score = np.cumsum(scores)\n",
    "ax4.plot(cumulative_score, color='purple', linewidth=2)\n",
    "ax4.set_title('Score Cumul√©')\n",
    "ax4.set_xlabel('√âpisode')\n",
    "ax4.set_ylabel('Score Total')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de l'entra√Ænement\n",
    "print(f\"\\nüìä STATISTIQUES DE L'ENTRA√éNEMENT SIMUL√â:\")\n",
    "print(f\"   ‚Ä¢ Score moyen final (100 derniers): {np.mean(scores[-100:]):.2f}\")\n",
    "print(f\"   ‚Ä¢ Meilleur score atteint: {max(scores):.1f}\")\n",
    "print(f\"   ‚Ä¢ √âpisode du meilleur score: {np.argmax(scores)}\")\n",
    "print(f\"   ‚Ä¢ Epsilon final: {epsilons[-1]:.4f}\")\n",
    "print(f\"   ‚Ä¢ Am√©lioration totale: {np.mean(scores[-100:]) - np.mean(scores[:100]):.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ PHASES D'APPRENTISSAGE:\")\n",
    "print(f\"   ‚Ä¢ Phase 1 (Exploration): Score moyen = {np.mean(scores[:500]):.2f}\")\n",
    "print(f\"   ‚Ä¢ Phase 2 (Apprentissage): Score moyen = {np.mean(scores[500:1500]):.2f}\")\n",
    "print(f\"   ‚Ä¢ Phase 3 (Convergence): Score moyen = {np.mean(scores[1500:]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8270d4f",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Algorithme DQN en D√©tail - Le C≈ìur de l'Apprentissage\n",
    "\n",
    "### ü§î Rappel : Comment un Humain Apprend √† Jouer ?\n",
    "\n",
    "Quand vous apprenez √† jouer √† Snake, votre cerveau fait ceci :\n",
    "1. **Vous regardez** la situation (o√π est le serpent, o√π est la pomme)\n",
    "2. **Vous estimez** : \"Si je vais √† droite, qu'est-ce qui va se passer ?\"\n",
    "3. **Vous choisissez** l'action qui semble la meilleure\n",
    "4. **Vous observez** le r√©sultat et vous ajustez votre jugement\n",
    "\n",
    "### üß† Le DQN Fait Pareil, Mais avec des Maths !\n",
    "\n",
    "Le **Deep Q-Network (DQN)** est un algorithme qui imite cette fa√ßon d'apprendre. Voici comment :\n",
    "\n",
    "#### üè∑Ô∏è La \"Table de Valeurs\" Magique\n",
    "\n",
    "Imaginez que vous avez un carnet avec **toutes les situations possibles** du jeu :\n",
    "- Page 1 : \"Serpent au centre, pomme √† droite, pas de danger\"\n",
    "- Page 2 : \"Serpent pr√®s du mur, pomme en bas, danger √† droite\"\n",
    "- etc...\n",
    "\n",
    "Sur chaque page, vous notez la **valeur** de chaque action :\n",
    "- Aller tout droit : 7/10\n",
    "- Aller √† droite : 3/10 (dangereux !)\n",
    "- Aller √† gauche : 8/10 (bon choix !)\n",
    "\n",
    "**C'est exactement ce que fait la fonction Q !**\n",
    "\n",
    "### üßÆ L'√âquation Magique (Sans Maths Compliqu√©es !)\n",
    "\n",
    "```\n",
    "Valeur d'une action = R√©compense imm√©diate + Valeur de la meilleure action suivante\n",
    "```\n",
    "\n",
    "**En fran√ßais :** \n",
    "- \"Cette action me donne +10 points maintenant...\"\n",
    "- \"...ET elle me met dans une position o√π je peux gagner 15 points de plus\"\n",
    "- \"DONC cette action vaut 25 points au total !\"\n",
    "\n",
    "### üîÑ Les 3 Innovations G√©niales du DQN\n",
    "\n",
    "#### 1. üíæ M√©moire √† Long Terme (Experience Replay)\n",
    "**Probl√®me humain :** Vous oubliez vos erreurs pass√©es\n",
    "**Solution DQN :** L'IA garde TOUTES ses exp√©riences dans un carnet et les relit r√©guli√®rement\n",
    "\n",
    "#### 2. üìö Professeur Stable (Target Network)  \n",
    "**Probl√®me humain :** Apprendre en changeant constamment les r√®gles\n",
    "**Solution DQN :** Un \"professeur\" stable donne les bonnes r√©ponses pendant que l'IA apprend\n",
    "\n",
    "#### 3. üé≤ Exploration Intelligente (Œµ-greedy)\n",
    "**Probl√®me humain :** Soit vous ne prenez jamais de risque, soit vous √™tes compl√®tement fou\n",
    "**Solution DQN :** 90% du temps ‚Üí choix intelligent, 10% du temps ‚Üí exp√©rimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéì √âCOLE DE L'IA : Comment DQN Apprend √âtape par √âtape\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "print(\"üè´ BIENVENUE √Ä L'√âCOLE DE L'IA !\")\n",
    "print(\"Aujourd'hui, nous allons voir comment notre IA apprend √† jouer √† Snake\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class EcoleDQN:\n",
    "    \"\"\"Version simplifi√©e et comment√©e de l'algorithme DQN pour d√©butants\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"üë∂ 1. CR√âATION D'UN NOUVEL √âL√àVE IA\")\n",
    "        \n",
    "        # üß† Param√®tres d'apprentissage (comme les r√©glages d'un √©l√®ve)\n",
    "        self.gamma = 0.9          # Combien l'IA pense au futur (0-1)\n",
    "        self.epsilon = 1.0        # Niveau de curiosit√© (1=tr√®s curieux, 0=pas du tout)\n",
    "        self.epsilon_decay = 0.995  # La curiosit√© diminue avec l'exp√©rience\n",
    "        self.epsilon_min = 0.01   # Minimum de curiosit√© (toujours un peu)\n",
    "        \n",
    "        # üìö Carnet de m√©moire (comme un journal d'apprentissage)\n",
    "        self.memoire = deque(maxlen=1000)  # Se souvient des 1000 derni√®res exp√©riences\n",
    "        \n",
    "        print(f\"   ‚úÖ √âl√®ve cr√©√© avec {self.gamma*100}% de vision du futur\")\n",
    "        print(f\"   ‚úÖ Curiosit√© initiale : {self.epsilon*100}%\")\n",
    "        print(f\"   ‚úÖ Carnet de m√©moire pour {len(self.memoire)} exp√©riences\")\n",
    "        \n",
    "    def noter_experience(self, situation_avant, action_choisie, note_recue, situation_apres, partie_finie):\n",
    "        \"\"\"üìù L'IA note une exp√©rience dans son carnet\"\"\"\n",
    "        self.memoire.append((situation_avant, action_choisie, note_recue, situation_apres, partie_finie))\n",
    "        print(f\"   üìî Exp√©rience not√©e : Action {action_choisie} ‚Üí Note {note_recue}\")\n",
    "        \n",
    "    def choisir_action(self, situation, cerveau_ia):\n",
    "        \"\"\"ü§î Comment l'IA choisit son prochain mouvement\"\"\"\n",
    "        \n",
    "        # üé≤ Jeu de hasard : explorer ou utiliser ses connaissances ?\n",
    "        if random.random() < self.epsilon:\n",
    "            # üé≠ Mode EXPLORATION : \"Je vais essayer quelque chose de nouveau !\"\n",
    "            action = random.randint(0, 2)\n",
    "            print(f\"   üé≤ EXPLORATION : Action al√©atoire {action}\")\n",
    "            return action\n",
    "        else:\n",
    "            # üß† Mode EXPLOITATION : \"Je vais faire ce que je pense √™tre le mieux !\"\n",
    "            with torch.no_grad():  # Pas besoin d'apprendre maintenant, juste d√©cider\n",
    "                situation_tensor = torch.FloatTensor(situation).unsqueeze(0)\n",
    "                valeurs_actions = cerveau_ia(situation_tensor)\n",
    "                action = valeurs_actions.argmax().item()\n",
    "                print(f\"   üß† R√âFLEXION : Meilleure action calcul√©e = {action}\")\n",
    "                return action\n",
    "    \n",
    "    def seance_apprentissage(self, cerveau_principal, cerveau_professeur, optimiseur):\n",
    "        \"\"\"üéì Une s√©ance d'apprentissage de l'IA\"\"\"\n",
    "        \n",
    "        if len(self.memoire) < 32:  # Pas assez d'exp√©riences pour apprendre\n",
    "            print(f\"   ‚è≥ Pas assez d'exp√©riences ({len(self.memoire)}/32 minimum)\")\n",
    "            return 0\n",
    "        \n",
    "        print(\"   üìö D√âBUT DE LA S√âANCE D'APPRENTISSAGE\")\n",
    "        \n",
    "        # üìñ Choisir 32 exp√©riences au hasard dans le carnet\n",
    "        batch_experiences = random.sample(self.memoire, 32)\n",
    "        print(\"   üìù 32 exp√©riences s√©lectionn√©es au hasard\")\n",
    "        \n",
    "        # üîÑ Organiser les exp√©riences par type d'information\n",
    "        situations_avant = torch.FloatTensor([exp[0] for exp in batch_experiences])\n",
    "        actions_faites = torch.LongTensor([exp[1] for exp in batch_experiences])\n",
    "        notes_recues = torch.FloatTensor([exp[2] for exp in batch_experiences])\n",
    "        situations_apres = torch.FloatTensor([exp[3] for exp in batch_experiences])\n",
    "        parties_finies = torch.BoolTensor([exp[4] for exp in batch_experiences])\n",
    "        \n",
    "        # üß† Que pensait l'IA √† l'√©poque ? (valeurs actuelles)\n",
    "        valeurs_pensees = cerveau_principal(situations_avant).gather(1, actions_faites.unsqueeze(1))\n",
    "        \n",
    "        # üë®‚Äçüè´ Que dit le professeur stable ? (valeurs cibles)\n",
    "        with torch.no_grad():  # Le professeur ne change pas pendant qu'il enseigne\n",
    "            valeurs_futures_max = cerveau_professeur(situations_apres).max(1)[0]\n",
    "            valeurs_cibles = notes_recues + (self.gamma * valeurs_futures_max * ~parties_finies)\n",
    "        \n",
    "        # üìä Calculer l'erreur (diff√©rence entre ce que l'IA pensait et la r√©alit√©)\n",
    "        erreur = F.mse_loss(valeurs_pensees.squeeze(), valeurs_cibles)\n",
    "        print(f\"   ‚ùå Erreur calcul√©e : {erreur.item():.6f}\")\n",
    "        \n",
    "        # üîß Corriger le cerveau de l'IA\n",
    "        optimiseur.zero_grad()  # Effacer les corrections pr√©c√©dentes\n",
    "        erreur.backward()       # Calculer les corrections n√©cessaires\n",
    "        optimiseur.step()       # Appliquer les corrections\n",
    "        print(\"   ‚úÖ Cerveau de l'IA mis √† jour !\")\n",
    "        \n",
    "        # üìâ R√©duire la curiosit√© (l'IA devient plus experte)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            print(f\"   üîç Curiosit√© r√©duite √† : {self.epsilon:.3f}\")\n",
    "            \n",
    "        return erreur.item()\n",
    "\n",
    "# üé¨ D√âMONSTRATION EN DIRECT !\n",
    "print(\"\\nüé¨ D√âMONSTRATION D'UNE S√âANCE D'APPRENTISSAGE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# üë®‚Äçüéì Cr√©er un nouvel √©l√®ve IA\n",
    "eleve_ia = EcoleDQN()\n",
    "\n",
    "# üß† Cr√©er les cerveaux (r√©seaux de neurones)\n",
    "cerveau_principal = DemoQNetwork()    # Le cerveau qui apprend\n",
    "cerveau_professeur = DemoQNetwork()   # Le professeur stable\n",
    "optimiseur = torch.optim.Adam(cerveau_principal.parameters(), lr=0.001)\n",
    "\n",
    "# üìã Le professeur copie les connaissances de l'√©l√®ve au d√©but\n",
    "cerveau_professeur.load_state_dict(cerveau_principal.state_dict())\n",
    "print(\"‚úÖ Professeur et √©l√®ve synchronis√©s\")\n",
    "\n",
    "# üìù Simuler quelques exp√©riences d'apprentissage\n",
    "print(f\"\\nüìö SIMULATION DE 5 EXP√âRIENCES DE JEU :\")\n",
    "experiences_exemples = [\n",
    "    {\"situation\": \"Pr√®s du mur\", \"action\": 1, \"note\": -10, \"resultat\": \"Collision !\"},\n",
    "    {\"situation\": \"Pomme visible\", \"action\": 0, \"note\": 0, \"resultat\": \"Se rapproche\"},\n",
    "    {\"situation\": \"Sur la pomme\", \"action\": 0, \"note\": 10, \"resultat\": \"Miam !\"},\n",
    "    {\"situation\": \"Queue proche\", \"action\": 2, \"note\": 0, \"resultat\": \"√âvite danger\"},\n",
    "    {\"situation\": \"Espace libre\", \"action\": 0, \"note\": 0, \"resultat\": \"Continue\"}\n",
    "]\n",
    "\n",
    "for i, exp in enumerate(experiences_exemples):\n",
    "    situation = np.random.random(11)  # Situation simul√©e\n",
    "    eleve_ia.noter_experience(situation, exp[\"action\"], exp[\"note\"], np.random.random(11), exp[\"note\"] == -10)\n",
    "    print(f\"   {i+1}. {exp['situation']} ‚Üí Action {exp['action']} ‚Üí {exp['resultat']} (Note: {exp['note']})\")\n",
    "\n",
    "print(f\"\\nüß† M√âMOIRE DE L'IA : {len(eleve_ia.memoire)} exp√©riences stock√©es\")\n",
    "\n",
    "# üéØ Test de prise de d√©cision\n",
    "print(f\"\\nüéØ TEST DE PRISE DE D√âCISION :\")\n",
    "situation_test = np.random.random(11)\n",
    "action_choisie = eleve_ia.choisir_action(situation_test, cerveau_principal)\n",
    "actions_noms = [\"Tout droit\", \"Droite\", \"Gauche\"]\n",
    "print(f\"   Dans une situation test, l'IA a choisi : {action_choisie} ({actions_noms[action_choisie]})\")\n",
    "\n",
    "print(f\"\\nüí™ L'IA EST PR√äTE √Ä APPRENDRE POUR DE VRAI !\")\n",
    "print(\"   üéÆ Dans le vrai jeu, elle va :\")\n",
    "print(\"   1. Jouer des milliers de parties\")\n",
    "print(\"   2. Noter chaque exp√©rience\") \n",
    "print(\"   3. Apprendre de ses erreurs\")\n",
    "print(\"   4. Devenir de plus en plus forte !\")\n",
    "\n",
    "print(f\"\\nüéì R√âSUM√â DE L'APPRENTISSAGE DQN :\")\n",
    "resume_points = [\n",
    "    \"L'IA a une M√âMOIRE pour se souvenir de ses exp√©riences\",\n",
    "    \"Elle EXPLORE au d√©but (actions al√©atoires) puis EXPLOITE ses connaissances\", \n",
    "    \"Un PROFESSEUR STABLE l'aide √† apprendre sans changer les r√®gles\",\n",
    "    \"Elle CALCULE la valeur de chaque action et choisit la meilleure\",\n",
    "    \"L'APPRENTISSAGE se fait par correction d'erreurs (comme √† l'√©cole !)\"\n",
    "]\n",
    "\n",
    "for i, point in enumerate(resume_points, 1):\n",
    "    print(f\"   {i}. {point}\")\n",
    "\n",
    "print(f\"\\nüöÄ Maintenant vous comprenez comment l'IA apprend !\")\n",
    "print(\"   Dans la suite, nous verrons comment l'utiliser concr√®tement !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3df42",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Guide d'Utilisation Pratique - Votre Premi√®re IA en Action !\n",
    "\n",
    "Maintenant que vous comprenez la th√©orie, il est temps de **mettre les mains dans le cambouis** ! Cette section vous guide pour utiliser le projet Snake RL **m√™me si vous n'avez jamais fait de programmation avanc√©e**.\n",
    "\n",
    "### üèÅ Objectif de cette Section\n",
    "\n",
    "√Ä la fin, vous saurez :\n",
    "- ‚úÖ **Installer** le projet sur votre ordinateur\n",
    "- ‚úÖ **Faire jouer** l'IA √† Snake\n",
    "- ‚úÖ **Comprendre** ce qui se passe pendant l'entra√Ænement\n",
    "- ‚úÖ **Comparer** votre IA avec d'autres joueurs\n",
    "- ‚úÖ **R√©soudre** les probl√®mes courants\n",
    "\n",
    "### üóÇÔ∏è Qu'est-ce qu'il y a dans le Projet ?\n",
    "\n",
    "Imaginez le projet comme une **bo√Æte √† outils** avec plusieurs compartiments :\n",
    "\n",
    "#### üìÅ Dossiers = Rangements\n",
    "- **`env/`** ‚Üí Le terrain de jeu (code du jeu Snake)\n",
    "- **`agent/`** ‚Üí Le cerveau de l'IA (r√©seau de neurones)\n",
    "- **`models/`** ‚Üí Le coffre-fort (sauvegarde des IA entra√Æn√©es)\n",
    "\n",
    "#### üêç Fichiers Python = Outils Sp√©cialis√©s\n",
    "- **`demo.py`** ‚Üí Testeur d'installation (\"Est-ce que tout marche ?\")\n",
    "- **`play_manual.py`** ‚Üí Mode humain (\"Jouer vous-m√™me\")\n",
    "- **`quick_train.py`** ‚Üí Entra√Æneur rapide (\"Cours IA, cours !\")\n",
    "- **`train.py`** ‚Üí Entra√Æneur complet (\"Formation intensive\")\n",
    "- **`test.py`** ‚Üí √âvaluateur (\"Montrer les performances\")\n",
    "\n",
    "### üéÆ Les 5 √âtapes du Succ√®s\n",
    "\n",
    "#### 1Ô∏è‚É£ **Installation** (5 minutes)\n",
    "```\n",
    "üîß But : Pr√©parer votre ordinateur\n",
    "üìù Action : Installer Python et les biblioth√®ques\n",
    "‚úÖ R√©sultat : Tous les outils pr√™ts √† l'emploi\n",
    "```\n",
    "\n",
    "#### 2Ô∏è‚É£ **Test Rapide** (2 minutes)  \n",
    "```\n",
    "üß™ But : V√©rifier que tout fonctionne\n",
    "üìù Action : Lancer demo.py\n",
    "‚úÖ R√©sultat : Message \"Tout marche parfaitement !\"\n",
    "```\n",
    "\n",
    "#### 3Ô∏è‚É£ **Exp√©rience Humaine** (5-10 minutes)\n",
    "```\n",
    "üéÆ But : Comprendre la difficult√© du jeu\n",
    "üìù Action : Jouer manuellement avec play_manual.py\n",
    "‚úÖ R√©sultat : Votre score de r√©f√©rence humain\n",
    "```\n",
    "\n",
    "#### 4Ô∏è‚É£ **Premier Entra√Ænement** (5-10 minutes)\n",
    "```\n",
    "‚ö° But : Voir l'IA apprendre rapidement  \n",
    "üìù Action : Lancer quick_train.py\n",
    "‚úÖ R√©sultat : Une IA entra√Æn√©e et ses courbes d'apprentissage\n",
    "```\n",
    "\n",
    "#### 5Ô∏è‚É£ **√âvaluation** (5 minutes)\n",
    "```\n",
    "üìä But : Voir si votre IA est dou√©e\n",
    "üìù Action : Lancer test.py\n",
    "‚úÖ R√©sultat : Score de l'IA vs score humain\n",
    "```\n",
    "\n",
    "### üí° Conseils pour R√©ussir\n",
    "\n",
    "#### üü¢ Ce qui est FACILE :\n",
    "- Suivre les instructions dans l'ordre\n",
    "- Copier-coller les commandes\n",
    "- Regarder les graphiques\n",
    "- Comparer les scores\n",
    "\n",
    "#### üü° Ce qui demande un PEU d'attention :\n",
    "- Installer Python si vous ne l'avez pas\n",
    "- Comprendre les messages d'erreur\n",
    "- Ajuster les param√®tres si n√©cessaire\n",
    "\n",
    "#### üî¥ Ce qui est AVANC√â (optionnel) :\n",
    "- Modifier le code source\n",
    "- Cr√©er ses propres am√©liorations\n",
    "- D√©boguer les probl√®mes complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ VOTRE FEUILLE DE ROUTE PERSONNALIS√âE\n",
    "print(\"üó∫Ô∏è GUIDE PRATIQUE COMPLET - √âTAPE PAR √âTAPE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üëã Bonjour ! Vous √™tes sur le point de cr√©er votre premi√®re IA !\")\n",
    "print(\"Suivez ce guide et dans 30 minutes, vous aurez une IA qui joue √† Snake !\")\n",
    "\n",
    "# √âTAPE 1 : V√©rification de l'environnement\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîß √âTAPE 1 : PR√âPARATION DE VOTRE ORDINATEUR\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìã LISTE DE V√âRIFICATION AVANT DE COMMENCER :\")\n",
    "checklist_pre = [\n",
    "    \"‚úÖ Vous avez Python install√© (version 3.8 ou plus r√©cente)\",\n",
    "    \"‚úÖ Vous savez ouvrir un terminal/invite de commande\",\n",
    "    \"‚úÖ Vous avez t√©l√©charg√© le projet Snake RL\",\n",
    "    \"‚úÖ Vous √™tes dans le dossier du projet\"\n",
    "]\n",
    "\n",
    "for item in checklist_pre:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "print(f\"\\n‚ùì PAS S√õR DE COMMENT FAIRE ? Voici de l'aide :\")\n",
    "help_steps = {\n",
    "    \"V√©rifier Python\": [\n",
    "        \"Ouvrez un terminal/invite de commande\",\n",
    "        \"Tapez : python --version\",\n",
    "        \"Vous devriez voir quelque chose comme 'Python 3.x.x'\"\n",
    "    ],\n",
    "    \"Ouvrir un terminal\": [\n",
    "        \"Windows : Appuyez Win+R, tapez 'cmd', Entr√©e\",\n",
    "        \"Mac : Cmd+Espace, tapez 'terminal', Entr√©e\", \n",
    "        \"Linux : Ctrl+Alt+T\"\n",
    "    ],\n",
    "    \"Naviguer vers le projet\": [\n",
    "        \"Utilisez 'cd' pour changer de dossier\",\n",
    "        \"Exemple : cd C:\\\\Mes_Projets\\\\Snake_RL\",\n",
    "        \"V√©rifiez avec 'ls' (Mac/Linux) ou 'dir' (Windows)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for help_topic, steps in help_steps.items():\n",
    "    print(f\"\\nüÜò {help_topic} :\")\n",
    "    for step in steps:\n",
    "        print(f\"   ‚Ä¢ {step}\")\n",
    "\n",
    "# √âTAPE 2 : Installation\n",
    "print(\"\\n\" + \"=\"*50)  \n",
    "print(\"üì¶ √âTAPE 2 : INSTALLATION DES OUTILS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIF : Donner √† Python tous les outils n√©cessaires\")\n",
    "print(\"\\nüíª COMMANDES √Ä EX√âCUTER (une par une) :\")\n",
    "\n",
    "installation_commands = [\n",
    "    {\n",
    "        \"commande\": \"pip install -r requirements.txt\",\n",
    "        \"explication\": \"Installe toutes les biblioth√®ques n√©cessaires\",\n",
    "        \"temps\": \"2-5 minutes\",\n",
    "        \"quoi_voir\": \"Pleins de lignes qui d√©filent, puis 'Successfully installed...'\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, cmd in enumerate(installation_commands, 1):\n",
    "    print(f\"\\n{i}. COMMANDE :\")\n",
    "    print(f\"   üíæ Tapez : {cmd['commande']}\")\n",
    "    print(f\"   üìù √áa fait quoi : {cmd['explication']}\")\n",
    "    print(f\"   ‚è±Ô∏è Temps d'attente : {cmd['temps']}\")\n",
    "    print(f\"   üëÄ Vous devriez voir : {cmd['quoi_voir']}\")\n",
    "\n",
    "# √âTAPE 3 : Premier test\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üß™ √âTAPE 3 : PREMIER TEST - EST-CE QUE √áA MARCHE ?\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIF : V√©rifier que l'installation s'est bien pass√©e\")\n",
    "print(\"\\nüíª COMMANDE √Ä EX√âCUTER :\")\n",
    "print(\"   python demo.py\")\n",
    "\n",
    "print(f\"\\nüéä SI TOUT VA BIEN, vous devriez voir :\")\n",
    "success_messages = [\n",
    "    \"‚úÖ Pygame charg√© - On peut dessiner le jeu !\",\n",
    "    \"‚úÖ PyTorch charg√© - Notre IA peut maintenant apprendre !\",\n",
    "    \"‚úÖ Tous les outils sont pr√™ts !\",\n",
    "    \"üéÆ D√©monstration du jeu...\",\n",
    "    \"üß† Test de l'agent DQN...\"\n",
    "]\n",
    "\n",
    "for msg in success_messages:\n",
    "    print(f\"   {msg}\")\n",
    "\n",
    "print(f\"\\nüò± SI √áA NE MARCHE PAS :\")\n",
    "troubleshooting = {\n",
    "    \"ModuleNotFoundError\": \"R√©essayez l'installation : pip install -r requirements.txt\",\n",
    "    \"pygame error\": \"Red√©marrez votre ordinateur et r√©essayez\",\n",
    "    \"torch error\": \"Votre Python est peut-√™tre trop ancien, essayez Python 3.8+\",\n",
    "    \"Autre erreur\": \"Copiez le message d'erreur et cherchez sur Google avec 'python'\"\n",
    "}\n",
    "\n",
    "for error, solution in troubleshooting.items():\n",
    "    print(f\"   ‚ùå {error:<20} ‚Üí {solution}\")\n",
    "\n",
    "# √âTAPE 4 : Jeu manuel\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéÆ √âTAPE 4 : JOUEZ VOUS-M√äME √Ä SNAKE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIF : Comprendre la difficult√© et √©tablir votre score de r√©f√©rence\")\n",
    "print(\"\\nüíª COMMANDE √Ä EX√âCUTER :\")\n",
    "print(\"   python play_manual.py\")\n",
    "\n",
    "print(f\"\\nüïπÔ∏è CONTR√îLES DU JEU :\")\n",
    "controls = {\n",
    "    \"Fl√®ches directionnelles\": \"D√©placer le serpent\",\n",
    "    \"Espace\": \"Red√©marrer la partie\",\n",
    "    \"√âchap\": \"Quitter le jeu\"\n",
    "}\n",
    "\n",
    "for control, action in controls.items():\n",
    "    print(f\"   üéÆ {control:<25} ‚Üí {action}\")\n",
    "\n",
    "print(f\"\\nüèÜ D√âFI PERSONNEL :\")\n",
    "print(\"   ‚Ä¢ Essayez d'obtenir un score de 5 (= 5 pommes mang√©es)\")\n",
    "print(\"   ‚Ä¢ Notez votre meilleur score quelque part\")\n",
    "print(\"   ‚Ä¢ Observez √† quel point c'est difficile !\")\n",
    "\n",
    "# √âTAPE 5 : Premier entra√Ænement\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üöÄ √âTAPE 5 : ENTRA√éNEMENT EXPRESS DE VOTRE IA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIF : Voir votre IA apprendre √† jouer en 5 minutes\")\n",
    "print(\"\\nüíª COMMANDE √Ä EX√âCUTER :\")\n",
    "print(\"   python quick_train.py\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è PENDANT L'ENTRA√éNEMENT (environ 5 minutes) :\")\n",
    "training_phases = [\n",
    "    \"Minutes 1-2 : L'IA fait n'importe quoi (score autour de 0)\",\n",
    "    \"Minutes 2-3 : Elle commence √† comprendre (score monte)\",  \n",
    "    \"Minutes 3-4 : Elle s'am√©liore rapidement (score = 2-5)\",\n",
    "    \"Minutes 4-5 : Elle se stabilise (score = 3-8)\"\n",
    "]\n",
    "\n",
    "for phase in training_phases:\n",
    "    print(f\"   üìä {phase}\")\n",
    "\n",
    "print(f\"\\nüéâ √Ä LA FIN, vous aurez :\")\n",
    "end_results = [\n",
    "    \"üìà Un graphique montrant l'apprentissage\",\n",
    "    \"üß† Une IA sauvegard√©e (fichier .pth)\",\n",
    "    \"üìä Les scores de chaque partie\"\n",
    "]\n",
    "\n",
    "for result in end_results:\n",
    "    print(f\"   {result}\")\n",
    "\n",
    "# √âTAPE 6 : Test de l'IA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üèÜ √âTAPE 6 : VOIR VOTRE IA EN ACTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüéØ OBJECTIF : Regarder votre IA jouer et voir si elle bat votre score\")\n",
    "print(\"\\nüíª COMMANDE √Ä EX√âCUTER :\")\n",
    "print(\"   python test.py\")\n",
    "\n",
    "print(f\"\\nüéÆ MENU DU PROGRAMME DE TEST :\")\n",
    "test_menu = {\n",
    "    \"1\": \"Regarder l'IA jouer (mode visuel)\",\n",
    "    \"2\": \"Comparer IA vs joueur al√©atoire\", \n",
    "    \"3\": \"Mode interactif (vous vs IA)\",\n",
    "    \"4\": \"Statistiques d√©taill√©es\"\n",
    "}\n",
    "\n",
    "for option, description in test_menu.items():\n",
    "    print(f\"   {option}. {description}\")\n",
    "\n",
    "print(f\"\\nüíØ QUESTIONS √Ä SE POSER :\")\n",
    "questions = [\n",
    "    \"L'IA obtient-elle un meilleur score que vous ?\",\n",
    "    \"Ses mouvements semblent-ils intelligents ?\",\n",
    "    \"Fait-elle des erreurs stupides ?\",\n",
    "    \"Pourrait-elle encore s'am√©liorer ?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"   ü§î {q}\")\n",
    "\n",
    "# R√©capitulatif final\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéä F√âLICITATIONS ! VOUS AVEZ CR√â√â VOTRE PREMI√àRE IA !\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n‚úÖ CE QUE VOUS AVEZ ACCOMPLI :\")\n",
    "achievements = [\n",
    "    \"Install√© un environnement de Machine Learning\",\n",
    "    \"Compris les bases de l'apprentissage par renforcement\",\n",
    "    \"Entra√Æn√© une IA qui apprend toute seule\",\n",
    "    \"Compar√© les performances humain vs machine\",\n",
    "    \"Utilis√© des algorithmes de recherche de pointe (DQN)\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"   üèÜ {achievement}\")\n",
    "\n",
    "print(f\"\\nüöÄ ET MAINTENANT ? PROCHAINES AVENTURES :\")\n",
    "next_steps = [\n",
    "    \"Essayez l'entra√Ænement complet (train.py) pendant 1-2h\",\n",
    "    \"Modifiez les param√®tres pour voir l'impact\",\n",
    "    \"Regardez le code pour comprendre comment √ßa marche\",\n",
    "    \"Partagez vos r√©sultats avec vos amis !\",\n",
    "    \"Explorez d'autres projets d'IA\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   üéØ {step}\")\n",
    "\n",
    "print(f\"\\nüí° AIDE-M√âMOIRE DES COMMANDES :\")\n",
    "commands_summary = {\n",
    "    \"Test d'installation\": \"python demo.py\",\n",
    "    \"Jeu manuel\": \"python play_manual.py\",\n",
    "    \"Entra√Ænement rapide\": \"python quick_train.py\", \n",
    "    \"Entra√Ænement complet\": \"python train.py\",\n",
    "    \"Test de l'IA\": \"python test.py\"\n",
    "}\n",
    "\n",
    "for purpose, command in commands_summary.items():\n",
    "    print(f\"   üîß {purpose:<20} : {command}\")\n",
    "\n",
    "print(f\"\\nüåü Vous faites maintenant partie de la communaut√© IA !\")\n",
    "print(\"   Bienvenue dans le futur ! ü§ñ‚ú®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87b881",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Et Apr√®s ? Am√©liorer Votre IA pour Devenir Expert\n",
    "\n",
    "F√©licitations ! Vous avez une IA qui joue √† Snake. Maintenant, voulez-vous la rendre **encore plus intelligente** ? Cette section vous montre comment passer de \"d√©butant\" √† \"expert\" en IA.\n",
    "\n",
    "### üéØ Pourquoi Am√©liorer Votre IA ?\n",
    "\n",
    "Votre IA actuelle est comme un **√©l√®ve de CP** qui vient d'apprendre √† lire. Elle peut jouer √† Snake, mais elle peut devenir bien plus forte ! Voici pourquoi c'est excitant :\n",
    "\n",
    "- üöÄ **D√©fis techniques** : R√©soudre des probl√®mes plus complexes\n",
    "- üß† **Apprentissage** : Comprendre des concepts avanc√©s d'IA\n",
    "- üèÜ **Performance** : Cr√©er une IA qui bat m√™me les meilleurs humains\n",
    "- üíº **Carri√®re** : Ces comp√©tences sont tr√®s demand√©es en entreprise\n",
    "\n",
    "### üéì Niveaux de Difficult√© : Choisissez Votre Aventure !\n",
    "\n",
    "#### üü¢ NIVEAU D√âBUTANT (1-2 semaines)\n",
    "**Pour ceux qui veulent exp√©rimenter sans se prendre la t√™te**\n",
    "\n",
    "‚úÖ **Ce que vous pouvez faire :**\n",
    "- Changer les param√®tres d'entra√Ænement (plus ou moins de curiosit√©)\n",
    "- Modifier la vitesse du jeu\n",
    "- Cr√©er des graphiques plus jolis\n",
    "- Organiser un tournoi entre amis\n",
    "\n",
    "üí° **Pourquoi c'est utile :** Vous comprenez l'impact de chaque param√®tre\n",
    "\n",
    "#### üü° NIVEAU INTERM√âDIAIRE (2-4 semaines)  \n",
    "**Pour ceux qui veulent vraiment am√©liorer l'IA**\n",
    "\n",
    "‚úÖ **Ce que vous pouvez faire :**\n",
    "- Impl√©menter **Double DQN** (technique d'am√©lioration simple)\n",
    "- Ajouter des obstacles dans le jeu\n",
    "- Cr√©er diff√©rentes tailles d'ar√®ne\n",
    "- Comparer plusieurs algorithmes\n",
    "\n",
    "üí° **Pourquoi c'est utile :** Votre IA devient significativement plus performante\n",
    "\n",
    "#### üî¥ NIVEAU AVANC√â (1-3 mois)\n",
    "**Pour les futurs experts en IA**\n",
    "\n",
    "‚úÖ **Ce que vous pouvez faire :**\n",
    "- Impl√©menter **Rainbow DQN** (technique de pointe)\n",
    "- Cr√©er un Snake multijoueur avec plusieurs IA\n",
    "- Publier vos r√©sultats en ligne\n",
    "- Contribuer √† des projets open source\n",
    "\n",
    "üí° **Pourquoi c'est utile :** Vous ma√Ætrisez les techniques professionnelles\n",
    "\n",
    "### üõ†Ô∏è Am√©liorations Concr√®tes (Par Ordre de Difficult√©)\n",
    "\n",
    "#### 1Ô∏è‚É£ **Tweaking** (Tr√®s Facile - 1 jour)\n",
    "```\n",
    "üéØ But : Optimiser les performances avec les param√®tres actuels\n",
    "üîß Comment : Modifier learning_rate, epsilon, gamma dans le code\n",
    "üìä R√©sultat attendu : +10-20% de performance\n",
    "```\n",
    "\n",
    "#### 2Ô∏è‚É£ **Double DQN** (Facile - 1 semaine)\n",
    "```  \n",
    "üéØ But : R√©duire les erreurs d'apprentissage\n",
    "üîß Comment : Utiliser deux r√©seaux qui se v√©rifient mutuellement\n",
    "üìä R√©sultat attendu : +20-30% de performance\n",
    "```\n",
    "\n",
    "#### 3Ô∏è‚É£ **Reward Shaping** (Moyen - 2 semaines)\n",
    "```\n",
    "üéØ But : Donner de meilleures \"notes\" √† l'IA\n",
    "üîß Comment : R√©compenser les bons comportements interm√©diaires\n",
    "üìä R√©sultat attendu : +30-50% de performance\n",
    "```\n",
    "\n",
    "#### 4Ô∏è‚É£ **Architecture** (Difficile - 1 mois)\n",
    "```\n",
    "üéØ But : Am√©liorer le \"cerveau\" de l'IA\n",
    "üîß Comment : R√©seaux plus sophistiqu√©s (CNN, attention, etc.)\n",
    "üìä R√©sultat attendu : +50-100% de performance\n",
    "```\n",
    "\n",
    "### üéÆ Nouvelles Variantes du Jeu\n",
    "\n",
    "Au lieu d'am√©liorer juste l'algorithme, vous pouvez cr√©er de **nouveaux d√©fis** :\n",
    "\n",
    "#### üèóÔ∏è **Snake avec Obstacles**\n",
    "- Ajouter des murs dans l'ar√®ne\n",
    "- L'IA doit apprendre √† naviguer autour\n",
    "\n",
    "#### üçé **Multi-Food Snake**\n",
    "- Plusieurs pommes en m√™me temps\n",
    "- L'IA doit optimiser son chemin\n",
    "\n",
    "#### üë• **Snake Collaboratif**\n",
    "- Plusieurs serpents qui s'entraident\n",
    "- Apprentissage social et coop√©ration\n",
    "\n",
    "#### ‚ö° **Snake Dynamique**\n",
    "- Vitesse qui change\n",
    "- Obstacles mobiles\n",
    "- D√©fis adaptatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24996f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ VOTRE PLAN D'AM√âLIORATION PERSONNALIS√â\n",
    "print(\"üöÄ COMMENT TRANSFORMER VOTRE IA EN CHAMPION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üéÆ Votre IA joue d√©j√† √† Snake, mais on peut faire TELLEMENT mieux !\")\n",
    "print(\"Voici un plan progressif pour passer de '√©l√®ve' √† 'ma√Ætre Jedi' !\")\n",
    "\n",
    "# Plan d'am√©lioration par √©tapes\n",
    "print(\"\\nüìà PLAN D'AM√âLIORATION PROGRESSIVE\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "improvement_levels = {\n",
    "    \"üü¢ SEMAINE 1-2 : Les Petits R√©glages\": {\n",
    "        \"description\": \"Optimiser sans coder\",\n",
    "        \"tasks\": [\n",
    "            \"Tester diff√©rentes vitesses d'apprentissage\",\n",
    "            \"Changer le niveau de curiosit√© (epsilon)\",\n",
    "            \"Modifier la taille du cerveau de l'IA\",\n",
    "            \"Cr√©er des graphiques plus beaux\"\n",
    "        ],\n",
    "        \"difficulte\": \"‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ\",\n",
    "        \"temps\": \"2-3 heures par weekend\",\n",
    "        \"resultat\": \"Score +10-20%\"\n",
    "    },\n",
    "    \n",
    "    \"üü° SEMAINE 3-6 : Les Vraies Am√©liorations\": {\n",
    "        \"description\": \"Am√©liorer l'algorithme\",\n",
    "        \"tasks\": [\n",
    "            \"Impl√©menter Double DQN (technique pro)\",\n",
    "            \"Ajouter des r√©compenses intelligentes\", \n",
    "            \"Cr√©er des niveaux de difficult√©\",\n",
    "            \"Comparer avec d'autres algorithmes\"\n",
    "        ],\n",
    "        \"difficulte\": \"‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ\",\n",
    "        \"temps\": \"5-10 heures par weekend\",\n",
    "        \"resultat\": \"Score +30-50%\"\n",
    "    },\n",
    "    \n",
    "    \"üî¥ MOIS 2-3 : Le Niveau Expert\": {\n",
    "        \"description\": \"Innovations et recherche\",\n",
    "        \"tasks\": [\n",
    "            \"Rainbow DQN (state-of-the-art)\",\n",
    "            \"Snake multijoueur collaboratif\",\n",
    "            \"Publication de vos r√©sultats\",\n",
    "            \"Contribution open source\"\n",
    "        ],\n",
    "        \"difficulte\": \"‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\",\n",
    "        \"temps\": \"Plusieurs heures par semaine\",\n",
    "        \"resultat\": \"Score +100%+ et reconnaissance\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for level, info in improvement_levels.items():\n",
    "    print(f\"\\n{level}\")\n",
    "    print(f\"   üéØ {info['description']}\")\n",
    "    print(f\"   üìä Difficult√© : {info['difficulte']}\")\n",
    "    print(f\"   ‚è∞ Temps requis : {info['temps']}\")\n",
    "    print(f\"   üèÜ R√©sultat attendu : {info['resultat']}\")\n",
    "    print(\"   üìù T√¢ches concr√®tes :\")\n",
    "    for task in info['tasks']:\n",
    "        print(f\"      ‚Ä¢ {task}\")\n",
    "\n",
    "# Premi√®re am√©lioration : Double DQN (exemple d√©taill√©)\n",
    "print(f\"\\nüéØ FOCUS : VOTRE PREMI√àRE VRAIE AM√âLIORATION - DOUBLE DQN\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "print(\"üí° CONCEPT SIMPLE :\")\n",
    "print(\"   Au lieu d'avoir 1 cerveau qui fait tout,\")\n",
    "print(\"   on en a 2 qui se v√©rifient mutuellement !\")\n",
    "print(\"   ‚Üí Plus pr√©cis, moins d'erreurs\")\n",
    "\n",
    "print(f\"\\nüîß CE QUI CHANGE DANS LE CODE (en fran√ßais) :\")\n",
    "double_dqn_steps = [\n",
    "    \"Au lieu de demander au m√™me cerveau 'Quelle action ?' et 'Combien √ßa vaut ?'\",\n",
    "    \"Cerveau Principal dit 'Je pense que la meilleure action est X'\",\n",
    "    \"Cerveau Professeur dit 'OK, mais moi je pense que X vaut Y points'\",\n",
    "    \"R√©sultat : √âvaluation plus objective et moins biais√©e\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(double_dqn_steps, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "print(f\"\\nüìä IMPACT TYPIQUE DE DOUBLE DQN :\")\n",
    "improvements_data = {\n",
    "    \"Score moyen avant\": \"5-8 pommes\",\n",
    "    \"Score moyen apr√®s\": \"8-12 pommes\", \n",
    "    \"Stabilit√©\": \"+40% moins de variations\",\n",
    "    \"Temps d'apprentissage\": \"25% plus rapide\",\n",
    "    \"Difficult√© impl√©mentation\": \"1 fonction √† modifier\"\n",
    "}\n",
    "\n",
    "for metric, value in improvements_data.items():\n",
    "    print(f\"   ‚Ä¢ {metric:<25}: {value}\")\n",
    "\n",
    "# Exemples d'exp√©rimentations faciles\n",
    "print(f\"\\nüß™ EXP√âRIMENTATIONS AMUSANTES (NIVEAU D√âBUTANT)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "easy_experiments = {\n",
    "    \"üéõÔ∏è Bataille des Param√®tres\": {\n",
    "        \"description\": \"Tester diff√©rents r√©glages\",\n",
    "        \"example\": \"IA_Rapide (lr=0.01) vs IA_Patiente (lr=0.0001)\",\n",
    "        \"temps\": \"1 soir√©e\",\n",
    "        \"fun_factor\": \"‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ\"\n",
    "    },\n",
    "    \n",
    "    \"üèÅ Course de Vitesse\": {\n",
    "        \"description\": \"Qui apprend le plus vite ?\",\n",
    "        \"example\": \"3 IA identiques, voir laquelle atteint score 10 en premier\",\n",
    "        \"temps\": \"1 weekend\", \n",
    "        \"fun_factor\": \"‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ\"\n",
    "    },\n",
    "    \n",
    "    \"üß† Tournoi des Architectures\": {\n",
    "        \"description\": \"Petits vs gros cerveaux\",\n",
    "        \"example\": \"R√©seau 64 neurones vs 256 vs 512\",\n",
    "        \"temps\": \"1 weekend\",\n",
    "        \"fun_factor\": \"‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\"\n",
    "    },\n",
    "    \n",
    "    \"üë• Humain vs Machine\": {\n",
    "        \"description\": \"Le d√©fi ultime !\",\n",
    "        \"example\": \"Vous + vos amis vs votre meilleure IA\",\n",
    "        \"temps\": \"1 soir√©e\",\n",
    "        \"fun_factor\": \"‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for experiment, details in easy_experiments.items():\n",
    "    print(f\"\\n{experiment}\")\n",
    "    print(f\"   üìù {details['description']}\")\n",
    "    print(f\"   üí° Exemple : {details['example']}\")\n",
    "    print(f\"   ‚è∞ Temps : {details['temps']}\")\n",
    "    print(f\"   üéâ Fun Factor : {details['fun_factor']}\")\n",
    "\n",
    "# Ressources pour apprendre\n",
    "print(f\"\\nüìö RESSOURCES POUR CONTINUER √Ä APPRENDRE\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "learning_resources = {\n",
    "    \"üé• Vid√©os (YouTube)\": [\n",
    "        \"3Blue1Brown - Neural Networks (comprendre les bases)\",\n",
    "        \"Two Minute Papers - Deep RL (voir les derni√®res avanc√©es)\",\n",
    "        \"Sentdex - Reinforcement Learning (tutoriels pratiques)\"\n",
    "    ],\n",
    "    \n",
    "    \"üìñ Cours en Ligne\": [\n",
    "        \"Coursera - Machine Learning (Andrew Ng)\",\n",
    "        \"edX - Introduction to Artificial Intelligence\", \n",
    "        \"Udacity - Deep Reinforcement Learning\"\n",
    "    ],\n",
    "    \n",
    "    \"üõ†Ô∏è Outils pour Exp√©rimenter\": [\n",
    "        \"OpenAI Gym - Plein d'environnements de jeu\",\n",
    "        \"Stable Baselines3 - Algorithmes RL pr√™ts √† utiliser\",\n",
    "        \"Weights & Biases - Suivre vos exp√©riences\"\n",
    "    ],\n",
    "    \n",
    "    \"üë• Communaut√©s\": [\n",
    "        \"Reddit r/MachineLearning\",\n",
    "        \"Discord serveurs IA/ML\",\n",
    "        \"GitHub - Contribuer √† des projets open source\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, resources in learning_resources.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for resource in resources:\n",
    "        print(f\"   ‚Ä¢ {resource}\")\n",
    "\n",
    "# Motivation finale\n",
    "print(f\"\\nüåü POURQUOI CONTINUER ? VOTRE FUTUR AVEC L'IA\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "future_benefits = [\n",
    "    \"üíº Carri√®re : L'IA est partout, ces comp√©tences sont tr√®s demand√©es\",\n",
    "    \"üß† Mental : R√©soudre des probl√®mes complexes, c'est satisfaisant !\",\n",
    "    \"üåç Impact : Vos IA peuvent aider √† r√©soudre de vrais probl√®mes\",\n",
    "    \"üë• Social : Rejoindre une communaut√© passionn√©e et cr√©ative\",\n",
    "    \"üéÆ Fun : Cr√©er des choses cool que vos amis admirent !\"\n",
    "]\n",
    "\n",
    "for benefit in future_benefits:\n",
    "    print(f\"   {benefit}\")\n",
    "\n",
    "print(f\"\\nüéØ D√âFI PERSONNEL :\")\n",
    "print(\"   Dans 1 mois, votre IA sera-t-elle capable de :\")\n",
    "print(\"   ‚Ä¢ Battre votre score humain de fa√ßon constante ?\")\n",
    "print(\"   ‚Ä¢ Jouer sans jamais mourir sur une petite ar√®ne ?\") \n",
    "print(\"   ‚Ä¢ Inspirer vos amis √† cr√©er leur propre IA ?\")\n",
    "\n",
    "print(f\"\\nüöÄ LE VOYAGE NE FAIT QUE COMMENCER !\")\n",
    "print(\"   Vous avez les bases, maintenant construisez votre empire IA ! üëë\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f45cd0",
   "metadata": {},
   "source": [
    "## üéâ F√©licitations ! Vous Venez de Cr√©er Votre Premi√®re IA\n",
    "\n",
    "### üèÜ Ce que Vous Avez Accompli (et c'est √âNORME !)\n",
    "\n",
    "Prenez une seconde pour r√©aliser ce que vous venez de faire. Il y a quelques heures, vous ne saviez peut-√™tre rien sur l'Intelligence Artificielle. Maintenant, vous avez :\n",
    "\n",
    "‚úÖ **Cr√©√© une vraie IA** qui apprend toute seule  \n",
    "‚úÖ **Compris l'apprentissage par renforcement** (un domaine de pointe !)  \n",
    "‚úÖ **Utilis√© des outils professionnels** (PyTorch, r√©seaux de neurones)  \n",
    "‚úÖ **Ma√Ætris√© le processus complet** (donn√©es ‚Üí entra√Ænement ‚Üí √©valuation)  \n",
    "‚úÖ **Compar√© humain vs machine** et vu qui gagne !  \n",
    "\n",
    "### üåü Vous Faites Maintenant Partie de l'√âlite\n",
    "\n",
    "Saviez-vous que moins de 1% de la population mondiale sait cr√©er une IA ? Vous venez de rejoindre un club tr√®s exclusif ! üé©‚ú®\n",
    "\n",
    "### üß† Les Concepts Que Vous Ma√Ætrisez Maintenant\n",
    "\n",
    "- **üéÆ Environnements d'apprentissage** : Comment structurer un probl√®me pour l'IA\n",
    "- **üß™ R√©seaux de neurones** : Le \"cerveau\" artificiel qui apprend\n",
    "- **üìä Fonctions de r√©compense** : Comment \"dresser\" une IA\n",
    "- **‚öñÔ∏è Exploration vs Exploitation** : L'√©quilibre entre curiosit√© et performance\n",
    "- **üìà M√©triques d'√©valuation** : Comment mesurer l'intelligence artificielle\n",
    "\n",
    "Ces concepts s'appliquent √† **tous** les domaines de l'IA moderne !\n",
    "\n",
    "### üöÄ Vos Nouvelles Superpowers\n",
    "\n",
    "Vous pouvez maintenant :\n",
    "\n",
    "#### üî¨ **Comprendre l'actualit√© IA**\n",
    "Quand vous entendez parler de ChatGPT, voitures autonomes, ou IA m√©dicale, vous comprenez les principes sous-jacents !\n",
    "\n",
    "#### üíº **Parler d'IA en entreprise**  \n",
    "Vous connaissez le vocabulaire, les d√©fis, et les possibilit√©s de l'IA appliqu√©e.\n",
    "\n",
    "#### üõ†Ô∏è **Cr√©er d'autres projets**\n",
    "Snake ‚Üí Pac-Man ‚Üí Jeux de plateau ‚Üí Robots ‚Üí Applications m√©tier !\n",
    "\n",
    "#### üéì **Apprendre plus facilement**\n",
    "Vous avez les fondations pour comprendre des sujets avanc√©s comme GPT, computer vision, etc.\n",
    "\n",
    "### üåç L'IA Change le Monde, et Vous en Faites Partie\n",
    "\n",
    "L'Intelligence Artificielle r√©volutionne :\n",
    "- **üè• M√©decine** : Diagnostic automatique, d√©couverte de m√©dicaments\n",
    "- **üöó Transport** : Voitures autonomes, optimisation du trafic  \n",
    "- **üéÆ Divertissement** : NPCs intelligents, g√©n√©ration de contenu\n",
    "- **üí∞ Finance** : Trading algorithmique, d√©tection de fraude\n",
    "- **üå± Environnement** : Optimisation √©nerg√©tique, pr√©diction climatique\n",
    "\n",
    "**Vous avez maintenant les cl√©s pour contribuer √† cette r√©volution !**\n",
    "\n",
    "### üéØ Votre Mission, Si Vous l'Acceptez\n",
    "\n",
    "1. **üì¢ Partagez votre succ√®s** : Montrez votre IA √† vos amis/famille\n",
    "2. **üî¨ Exp√©rimentez** : Modifiez les param√®tres, observez les effets\n",
    "3. **üìö Continuez √† apprendre** : Il y a tant d'autres domaines passionnants !\n",
    "4. **üë• Rejoignez la communaut√©** : Forums, Discord, projets open source\n",
    "5. **üåü Inspirez d'autres** : Votre histoire peut motiver quelqu'un d'autre\n",
    "\n",
    "### üí´ Derniers Mots d'Encouragement\n",
    "\n",
    "Rappelez-vous :\n",
    "- **üê£ Chaque expert √©tait un d√©butant** : Les cr√©ateurs de ChatGPT ont commenc√© comme vous\n",
    "- **üöÄ L'IA √©volue vite** : Ce que vous apprenez aujourd'hui vous sera utile demain\n",
    "- **üéÆ C'est amusant** : L'IA, c'est comme un jeu vid√©o grandeur nature !\n",
    "- **üåü Vous avez du potentiel** : Si vous √™tes arriv√© jusqu'ici, vous pouvez aller beaucoup plus loin\n",
    "\n",
    "---\n",
    "\n",
    "### üêç Merci d'Avoir Suivi Ce Voyage !\n",
    "\n",
    "De notre premi√®re explication sur \"qu'est-ce que l'apprentissage par renforcement\" √† votre IA fonctionnelle, nous avons fait un sacr√© chemin ensemble !\n",
    "\n",
    "**Votre IA joue maintenant √† Snake. Demain, qui sait ? Peut-√™tre qu'elle changera le monde ! üåç‚ú®**\n",
    "\n",
    "*‚Äî L'√©quipe Snake RL* ü§ñ‚ù§Ô∏è\n",
    "\n",
    "---\n",
    "\n",
    "**üé™ P.S. :** N'oubliez pas de faire une capture d'√©cran de votre meilleur score d'IA. Dans quelques ann√©es, quand vous serez expert en IA, ce sera un souvenir pr√©cieux de vos d√©buts ! üì∏üèÜ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
